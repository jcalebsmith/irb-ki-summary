[
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01WX4hZuT8ag6AXGDzWLY5A2",
        "type": "tool_result",
        "content": "     1→#!/usr/bin/env npx tsx\n     2→import { \n     3→  executeStreamingResearch,\n     4→  ResearchEventType,\n     5→  ResearchEvent\n     6→} from '../networks/streamingResearchNetwork';\n     7→import * as dotenv from 'dotenv';\n     8→import * as path from 'path';\n     9→import * as fs from 'fs/promises';\n    10→import { neo4jStorage } from '../storage/neo4jStorage';\n    11→\n    12→// Load environment variables\n    13→dotenv.config({ path: path.resolve(process.cwd(), '.env') });\n    14→\n    15→// Configuration\n    16→const CONFIG = {\n    17→  // Default research query if none provided\n    18→  defaultQuery: 'What are the latest breakthroughs in quantum computing for 2024, and how do they impact practical applications?',\n    19→  \n    20→  // Research parameters\n    21→  maxIterations: 3,\n    22→  qualityThreshold: 75,\n    23→  parallelAgents: 3,\n    24→  progressiveReports: true,\n    25→  \n    26→  // Output configuration\n    27→  outputDir: path.join(process.cwd(), 'research-baselines'),\n    28→  saveBaseline: true,\n    29→  showRealTimeEvents: true,\n    30→  showProgressBar: true,\n    31→  \n    32→  // Timeout configuration (minutes)\n    33→  timeoutMinutes: 15\n    34→};\n    35→\n    36→// ANSI color codes for terminal output\n    37→const colors = {\n    38→  reset: '\\x1b[0m',\n    39→  bright: '\\x1b[1m',\n    40→  dim: '\\x1b[2m',\n    41→  red: '\\x1b[31m',\n    42→  green: '\\x1b[32m',\n    43→  yellow: '\\x1b[33m',\n    44→  blue: '\\x1b[34m',\n    45→  magenta: '\\x1b[35m',\n    46→  cyan: '\\x1b[36m',\n    47→  white: '\\x1b[37m'\n    48→};\n    49→\n    50→// Progress tracking\n    51→interface ResearchMetrics {\n    52→  startTime: number;\n    53→  endTime?: number;\n    54→  totalDuration?: number;\n    55→  events: ResearchEvent[];\n    56→  insights: any[];\n    57→  graphMetrics?: {\n    58→    nodes: number;\n    59→    relationships: number;\n    60→    coherence: number;\n    61→  };\n    62→  qualityScores: number[];\n    63→  finalReport?: string;\n    64→  iterations: number;\n    65→  agentsActivated: Set<string>;\n    66→  errorCount: number;\n    67→}\n    68→\n    69→// Format time elapsed\n    70→function formatTime(ms: number): string {\n    71→  const seconds = Math.floor(ms / 1000);\n    72→  const minutes = Math.floor(seconds / 60);\n    73→  const remainingSeconds = seconds % 60;\n    74→  return minutes > 0 \n    75→    ? `${minutes}m ${remainingSeconds}s`\n    76→    : `${remainingSeconds}s`;\n    77→}\n    78→\n    79→// Create progress bar\n    80→function createProgressBar(current: number, total: number, width: number = 30): string {\n    81→  const percentage = Math.min(100, Math.round((current / total) * 100));\n    82→  const filled = Math.round((percentage / 100) * width);\n    83→  const empty = width - filled;\n    84→  \n    85→  const bar = '█'.repeat(filled) + '░'.repeat(empty);\n    86→  return `[${bar}] ${percentage}%`;\n    87→}\n    88→\n    89→// Log with timestamp and color\n    90→function log(message: string, color: string = colors.white, prefix: string = '') {\n    91→  const timestamp = new Date().toISOString().split('T')[1].split('.')[0];\n    92→  console.log(`${colors.dim}[${timestamp}]${colors.reset} ${prefix}${color}${message}${colors.reset}`);\n    93→}\n    94→\n    95→// Main research execution\n    96→async function runResearchQuery(query: string): Promise<ResearchMetrics> {\n    97→  const metrics: ResearchMetrics = {\n    98→    startTime: Date.now(),\n    99→    events: [],\n   100→    insights: [],\n   101→    qualityScores: [],\n   102→    iterations: 0,\n   103→    agentsActivated: new Set(),\n   104→    errorCount: 0\n   105→  };\n   106→\n   107→  log(`Starting Deep Research Pipeline`, colors.bright + colors.cyan, '🚀 ');\n   108→  log(`Query: \"${query}\"`, colors.white);\n   109→  log(`Configuration:`, colors.dim);\n   110→  log(`  Max Iterations: ${CONFIG.maxIterations}`, colors.dim);\n   111→  log(`  Quality Threshold: ${CONFIG.qualityThreshold}`, colors.dim);\n   112→  log(`  Parallel Agents: ${CONFIG.parallelAgents}`, colors.dim);\n   113→  console.log('');\n   114→\n   115→  // Create abort controller for timeout\n   116→  const abortController = new AbortController();\n   117→  const timeout = setTimeout(() => {\n   118→    log(`Research timeout reached (${CONFIG.timeoutMinutes} minutes)`, colors.yellow, '⏱️ ');\n   119→    abortController.abort();\n   120→  }, CONFIG.timeoutMinutes * 60 * 1000);\n   121→\n   122→  try {\n   123→    // Execute streaming research\n   124→    for await (const event of executeStreamingResearch(query, {\n   125→      maxIterations: CONFIG.maxIterations,\n   126→      qualityThreshold: CONFIG.qualityThreshold,\n   127→      parallelAgents: CONFIG.parallelAgents,\n   128→      progressiveReports: CONFIG.progressiveReports,\n   129→      abortSignal: abortController.signal\n   130→    })) {\n   131→      metrics.events.push(event);\n   132→      const elapsed = Date.now() - metrics.startTime;\n   133→      const elapsedStr = formatTime(elapsed);\n   134→\n   135→      // Handle different event types\n   136→      switch (event.type) {\n   137→        case ResearchEventType.RESEARCH_STARTED:\n   138→          log(`Research initialized`, colors.green, '✅ ');\n   139→          break;\n   140→\n   141→        case ResearchEventType.AGENT_ACTIVATED:\n   142→          if (event.agentName) {\n   143→            metrics.agentsActivated.add(event.agentName);\n   144→            if (CONFIG.showRealTimeEvents) {\n   145→              log(`Agent: ${event.agentName}`, colors.blue, '🤖 ');\n   146→            }\n   147→          }\n   148→          break;\n   149→\n   150→        case ResearchEventType.INSIGHT_DISCOVERED:\n   151→          metrics.insights.push(event.data);\n   152→          if (CONFIG.showRealTimeEvents) {\n   153→            const insightPreview = event.data?.insight \n   154→              ? event.data.insight.substring(0, 80) + (event.data.insight.length > 80 ? '...' : '')\n   155→              : 'New insight';\n   156→            log(`Insight: ${insightPreview}`, colors.magenta, '💡 ');\n   157→          }\n   158→          \n   159→          // Show progress bar\n   160→          if (CONFIG.showProgressBar && metrics.iterations > 0) {\n   161→            const progress = metrics.insights.length;\n   162→            const estimatedTotal = metrics.iterations * 10; // Estimate based on iteration\n   163→            const progressBar = createProgressBar(progress, estimatedTotal);\n   164→            process.stdout.write(`\\r${colors.cyan}Progress: ${progressBar} | ${metrics.insights.length} insights | ${elapsedStr}${colors.reset}`);\n   165→          }\n   166→          break;\n   167→\n   168→        case ResearchEventType.GRAPH_UPDATED:\n   169→          if (event.data) {\n   170→            metrics.graphMetrics = {\n   171→              nodes: event.data.nodes || 0,\n   172→              relationships: event.data.relationships || 0,\n   173→              coherence: event.data.coherence || 0\n   174→            };\n   175→            if (CONFIG.showRealTimeEvents) {\n   176→              log(`Graph: ${metrics.graphMetrics.nodes} nodes, ${metrics.graphMetrics.relationships} edges`, colors.cyan, '🔗 ');\n   177→            }\n   178→          }\n   179→          break;\n   180→\n   181→        case ResearchEventType.QUALITY_ASSESSED:\n   182→          const qualityScore = event.data?.scores?.overallQuality || 0;\n   183→          metrics.qualityScores.push(qualityScore);\n   184→          log(`Quality Score: ${qualityScore}/${CONFIG.qualityThreshold}`, \n   185→            qualityScore >= CONFIG.qualityThreshold ? colors.green : colors.yellow, \n   186→            '📊 ');\n   187→          break;\n   188→\n   189→        case ResearchEventType.ITERATION_COMPLETE:\n   190→          metrics.iterations++;\n   191→          console.log(''); // Clear progress bar line\n   192→          log(`Iteration ${metrics.iterations} complete`, colors.white, '🔄 ');\n   193→          break;\n   194→\n   195→        case ResearchEventType.RESEARCH_COMPLETE:\n   196→          clearTimeout(timeout);\n   197→          console.log(''); // Clear progress bar line\n   198→          log(`Research Complete!`, colors.bright + colors.green, '🏁 ');\n   199→          \n   200→          // Extract final report if available\n   201→          if (event.data?.report) {\n   202→            metrics.finalReport = event.data.report;\n   203→          }\n   204→          break;\n   205→\n   206→        case ResearchEventType.ERROR_OCCURRED:\n   207→          metrics.errorCount++;\n   208→          log(`Error: ${event.data?.error || 'Unknown error'}`, colors.red, '❌ ');\n   209→          break;\n   210→      }\n   211→    }\n   212→\n   213→  } catch (error: any) {\n   214→    if (error.name === 'AbortError') {\n   215→      log(`Research aborted (timeout or user cancellation)`, colors.yellow, '⚠️ ');\n   216→    } else {\n   217→      log(`Research failed: ${error.message}`, colors.red, '❌ ');\n   218→      throw error;\n   219→    }\n   220→  } finally {\n   221→    clearTimeout(timeout);\n   222→    metrics.endTime = Date.now();\n   223→    metrics.totalDuration = metrics.endTime - metrics.startTime;\n   224→  }\n   225→\n   226→  return metrics;\n   227→}\n   228→\n   229→// Save baseline results\n   230→async function saveBaseline(query: string, metrics: ResearchMetrics): Promise<string> {\n   231→  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n   232→  const filename = `baseline-${timestamp}.json`;\n   233→  const filepath = path.join(CONFIG.outputDir, filename);\n   234→\n   235→  // Ensure output directory exists\n   236→  await fs.mkdir(CONFIG.outputDir, { recursive: true });\n   237→\n   238→  // Prepare baseline data\n   239→  const baseline = {\n   240→    timestamp: new Date().toISOString(),\n   241→    query,\n   242→    configuration: {\n   243→      maxIterations: CONFIG.maxIterations,\n   244→      qualityThreshold: CONFIG.qualityThreshold,\n   245→      parallelAgents: CONFIG.parallelAgents\n   246→    },\n   247→    metrics: {\n   248→      duration: metrics.totalDuration,\n   249→      iterations: metrics.iterations,\n   250→      totalEvents: metrics.events.length,\n   251→      totalInsights: metrics.insights.length,\n   252→      agentsActivated: Array.from(metrics.agentsActivated),\n   253→      errorCount: metrics.errorCount,\n   254→      averageQuality: metrics.qualityScores.length > 0 \n   255→        ? metrics.qualityScores.reduce((a, b) => a + b, 0) / metrics.qualityScores.length \n   256→        : 0,\n   257→      finalQuality: metrics.qualityScores[metrics.qualityScores.length - 1] || 0,\n   258→      graphMetrics: metrics.graphMetrics\n   259→    },\n   260→    insights: metrics.insights,\n   261→    report: metrics.finalReport,\n   262→    events: CONFIG.saveBaseline ? metrics.events : undefined\n   263→  };\n   264→\n   265→  // Save to file\n   266→  await fs.writeFile(filepath, JSON.stringify(baseline, null, 2));\n   267→  \n   268→  // Also save the report as markdown if available\n   269→  if (metrics.finalReport) {\n   270→    const reportPath = path.join(CONFIG.outputDir, `report-${timestamp}.md`);\n   271→    await fs.writeFile(reportPath, metrics.finalReport);\n   272→    return `${filepath} and ${reportPath}`;\n   273→  }\n   274→\n   275→  return filepath;\n   276→}\n   277→\n   278→// Display final report\n   279→function displayReport(metrics: ResearchMetrics) {\n   280→  console.log('\\n' + '='.repeat(80));\n   281→  console.log(colors.bright + colors.cyan + 'FINAL RESEARCH REPORT' + colors.reset);\n   282→  console.log('='.repeat(80) + '\\n');\n   283→\n   284→  // Display metrics summary\n   285→  console.log(colors.bright + 'Research Metrics:' + colors.reset);\n   286→  console.log(`  Duration: ${formatTime(metrics.totalDuration || 0)}`);\n   287→  console.log(`  Iterations: ${metrics.iterations}`);\n   288→  console.log(`  Total Insights: ${metrics.insights.length}`);\n   289→  console.log(`  Agents Used: ${metrics.agentsActivated.size} (${Array.from(metrics.agentsActivated).join(', ')})`);\n   290→  console.log(`  Final Quality: ${metrics.qualityScores[metrics.qualityScores.length - 1] || 'N/A'}/100`);\n   291→  \n   292→  if (metrics.graphMetrics) {\n   293→    console.log(`  Knowledge Graph: ${metrics.graphMetrics.nodes} entities, ${metrics.graphMetrics.relationships} relationships`);\n   294→    console.log(`  Graph Coherence: ${(metrics.graphMetrics.coherence * 100).toFixed(1)}%`);\n   295→  }\n   296→\n   297→  // Display the actual report content\n   298→  if (metrics.finalReport) {\n   299→    console.log('\\n' + colors.bright + 'Report Content:' + colors.reset);\n   300→    console.log('-'.repeat(80));\n   301→    console.log(metrics.finalReport);\n   302→    console.log('-'.repeat(80));\n   303→  } else {\n   304→    console.log('\\n' + colors.yellow + 'No final report generated' + colors.reset);\n   305→    \n   306→    // Show top insights instead\n   307→    if (metrics.insights.length > 0) {\n   308→      console.log('\\n' + colors.bright + 'Top Insights Discovered:' + colors.reset);\n   309→      metrics.insights.slice(0, 5).forEach((insight, i) => {\n   310→        console.log(`${i + 1}. ${insight.insight || insight}`);\n   311→        if (insight.confidence) {\n   312→          console.log(`   Confidence: ${(insight.confidence * 100).toFixed(0)}%`);\n   313→        }\n   314→      });\n   315→    }\n   316→  }\n   317→\n   318→  console.log('\\n' + '='.repeat(80) + '\\n');\n   319→}\n   320→\n   321→// Main execution\n   322→async function main() {\n   323→  // Check environment\n   324→  console.log(colors.dim + 'Environment Check:' + colors.reset);\n   325→  console.log(`  EXA_API_KEY: ${process.env.EXA_API_KEY ? '✅' : '❌'}`);\n   326→  console.log(`  OPENAI_API_KEY: ${process.env.OPENAI_API_KEY ? '✅' : '❌'}`);\n   327→  console.log(`  NEO4J_URI: ${process.env.NEO4J_URI ? '✅' : '❌'}`);\n   328→  console.log('');\n   329→\n   330→  // Get query from command line or use default\n   331→  const query = process.argv[2] || CONFIG.defaultQuery;\n   332→\n   333→  try {\n   334→    // Test Neo4j connection if configured\n   335→    if (process.env.NEO4J_URI) {\n   336→      log('Testing knowledge graph database connection...', colors.dim);\n   337→      const isConnected = await neo4jStorage.testConnection();\n   338→      if (!isConnected) {\n   339→        log('Warning: Neo4j connection failed, continuing without graph', colors.yellow);\n   340→      }\n   341→    }\n   342→\n   343→    // Run the research\n   344→    const metrics = await runResearchQuery(query);\n   345→\n   346→    // Display the report\n   347→    displayReport(metrics);\n   348→\n   349→    // Save baseline if configured\n   350→    if (CONFIG.saveBaseline) {\n   351→      const savedPath = await saveBaseline(query, metrics);\n   352→      log(`Baseline saved to: ${savedPath}`, colors.green, '💾 ');\n   353→    }\n   354→\n   355→    // Cleanup\n   356→    if (process.env.NEO4J_URI) {\n   357→      await neo4jStorage.close();\n   358→    }\n   359→\n   360→    // Exit successfully\n   361→    process.exit(0);\n   362→\n   363→  } catch (error: any) {\n   364→    console.error(colors.red + 'Fatal error:' + colors.reset, error.message);\n   365→    \n   366→    // Cleanup on error\n   367→    try {\n   368→      await neo4jStorage.close();\n   369→    } catch {}\n   370→    \n   371→    process.exit(1);\n   372→  }\n   373→}\n   374→\n   375→// Handle interrupts gracefully\n   376→process.on('SIGINT', async () => {\n   377→  console.log('\\n' + colors.yellow + 'Research interrupted by user' + colors.reset);\n   378→  try {\n   379→    await neo4jStorage.close();\n   380→  } catch {}\n   381→  process.exit(0);\n   382→});\n   383→\n   384→// Run if executed directly\n   385→import { fileURLToPath } from 'url';\n   386→if (process.argv[1] === fileURLToPath(import.meta.url)) {\n   387→  main().catch(console.error);\n   388→}\n   389→\n   390→export { runResearchQuery, saveBaseline, CONFIG };\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01YGRxGoet9mt8pvTX4WUGNt",
        "type": "tool_result",
        "content": "     1→import { AgentNetwork } from '@mastra/core/network';\n     2→import { openai } from '@ai-sdk/openai';\n     3→import { z } from 'zod';\n     4→import { researchCoordinatorAgent } from '../agents/researchCoordinatorAgent';\n     5→import { qualityAssessmentAgent } from '../agents/qualityAssessmentAgent';\n     6→import { refinementAgent } from '../agents/refinementAgent';\n     7→import { researchAgent } from '../agents/researchAgent';\n     8→import { streamingResearchAgent, extractInsightsFromText } from '../agents/streamingResearchAgent';\n     9→import { reportAgent } from '../agents/reportAgent';\n    10→import { evaluationAgent } from '../agents/evaluationAgent';\n    11→import { learningExtractionAgent } from '../agents/learningExtractionAgent';\n    12→import { webSummarizationAgent } from '../agents/webSummarizationAgent';\n    13→import { knowledgeGraphAgent, buildKnowledgeGraph, KnowledgeGraph } from '../agents/knowledgeGraphAgent';\n    14→import { neo4jStorage } from '../storage/neo4jStorage';\n    15→import { StreamingKnowledgeGraphAgent } from '../agents/streamingKnowledgeGraphAgent';\n    16→\n    17→// Event types for streaming\n    18→export enum ResearchEventType {\n    19→  RESEARCH_STARTED = 'research_started',\n    20→  AGENT_ACTIVATED = 'agent_activated',\n    21→  INSIGHT_DISCOVERED = 'insight_discovered',\n    22→  GRAPH_UPDATED = 'graph_updated',\n    23→  QUALITY_ASSESSED = 'quality_assessed',\n    24→  ITERATION_COMPLETE = 'iteration_complete',\n    25→  RESEARCH_COMPLETE = 'research_complete',\n    26→  ERROR_OCCURRED = 'error_occurred',\n    27→  EVALUATION_PERFORMED = 'evaluation_performed',\n    28→  LEARNING_EXTRACTED = 'learning_extracted',\n    29→  WEB_SUMMARIZED = 'web_summarized'\n    30→}\n    31→\n    32→export interface ResearchEvent {\n    33→  type: ResearchEventType;\n    34→  timestamp: string;\n    35→  data: any;\n    36→  agentName?: string;\n    37→  confidence?: number;\n    38→}\n    39→\n    40→// Schema for streaming research state\n    41→const StreamingResearchState = z.object({\n    42→  query: z.string(),\n    43→  status: z.enum(['initializing', 'researching', 'refining', 'synthesizing', 'complete']),\n    44→  currentIteration: z.number(),\n    45→  qualityScore: z.number(),\n    46→  insights: z.array(z.object({\n    47→    insight: z.string(),\n    48→    confidence: z.number(),\n    49→    timestamp: z.string(),\n    50→    source: z.string()\n    51→  })),\n    52→  graph: z.object({\n    53→    nodes: z.number(),\n    54→    relationships: z.number(),\n    55→    coherence: z.number()\n    56→  }).optional(),\n    57→  errors: z.array(z.string())\n    58→});\n    59→\n    60→export const streamingResearchNetwork = new AgentNetwork({\n    61→  name: 'Streaming Research Network',\n    62→  agents: [\n    63→    researchCoordinatorAgent,\n    64→    researchAgent,\n    65→    qualityAssessmentAgent,\n    66→    refinementAgent,\n    67→    evaluationAgent,\n    68→    learningExtractionAgent,\n    69→    webSummarizationAgent,\n    70→    reportAgent,\n    71→    knowledgeGraphAgent,\n    72→  ],\n    73→  model: openai('gpt-4.1'),\n    74→  instructions: `\n    75→    You are a streaming research coordination system that provides real-time updates as research progresses.\n    76→    \n    77→    Your available agents are:\n    78→    1. Research Coordinator Agent: Creates research plans and determines quality criteria\n    79→    2. Research Agent: Conducts the actual research using web search and synthesis\n    80→    3. Quality Assessment Agent: Evaluates research completeness and quality\n    81→    4. Refinement Agent: Generates targeted queries to address gaps\n    82→    5. Evaluation Agent: Assesses relevance of search results\n    83→    6. Learning Extraction Agent: Extracts key learnings and generates follow-up questions\n    84→    7. Web Summarization Agent: Compresses web content while preserving critical information\n    85→    8. Report Agent: Generates comprehensive reports from research data\n    86→    9. Knowledge Graph Agent: Builds semantic knowledge graphs for deep understanding\n    87→    \n    88→    Key Capabilities:\n    89→    1. Stream research events as they occur\n    90→    2. Execute agents in parallel when possible\n    91→    3. Provide progressive insights and graph updates\n    92→    4. Enable early termination with partial results\n    93→    5. Support interactive refinement based on user feedback\n    94→    \n    95→    Parallel Execution Strategy:\n    96→    - Research multiple queries simultaneously\n    97→    - Build graph incrementally as data arrives\n    98→    - Assess quality continuously, not just at boundaries\n    99→    - Stream insights immediately upon discovery\n   100→    \n   101→    Always prioritize user experience through immediate feedback and progressive enhancement.\n   102→  `,\n   103→});\n   104→\n   105→// Main streaming execution function with semantic synthesis\n   106→export async function* executeStreamingResearch(\n   107→  query: string,\n   108→  options: {\n   109→    maxIterations?: number;\n   110→    qualityThreshold?: number;\n   111→    parallelAgents?: number;\n   112→    abortSignal?: AbortSignal;\n   113→    progressiveReports?: boolean;\n   114→  } = {}\n   115→): AsyncGenerator<ResearchEvent, void, unknown> {\n   116→  const maxIterations = options.maxIterations || 3;\n   117→  const qualityThreshold = options.qualityThreshold || 75;\n   118→  const parallelAgents = options.parallelAgents || 3;\n   119→  const progressiveReports = options.progressiveReports !== false;\n   120→  const abortSignal = options.abortSignal;\n   121→  \n   122→  // Initialize streaming knowledge graph for real-time processing\n   123→  const streamingGraph = new StreamingKnowledgeGraphAgent(query);\n   124→  let knowledgeGraph: KnowledgeGraph | null = null;\n   125→  let currentQualityScore = 0;\n   126→  let iterationCount = 0;\n   127→  let isAborted = false;\n   128→  \n   129→  // Non-blocking event queue for true streaming\n   130→  const eventQueue: ResearchEvent[] = [];\n   131→  let eventQueueResolver: ((value: void) => void) | null = null;\n   132→  \n   133→  // Check for abort signal\n   134→  if (abortSignal) {\n   135→    abortSignal.addEventListener('abort', () => {\n   136→      isAborted = true;\n   137→    });\n   138→  }\n   139→  \n   140→  try {\n   141→    // Emit start event\n   142→    yield {\n   143→      type: ResearchEventType.RESEARCH_STARTED,\n   144→      timestamp: new Date().toISOString(),\n   145→      data: { query, options: { maxIterations, qualityThreshold, parallelAgents } }\n   146→    };\n   147→    \n   148→    // Step 1: Create research plan (streamed)\n   149→    yield {\n   150→      type: ResearchEventType.AGENT_ACTIVATED,\n   151→      timestamp: new Date().toISOString(),\n   152→      agentName: 'Research Coordinator',\n   153→      data: { action: 'Creating research plan' }\n   154→    };\n   155→    \n   156→    const researchPlan = await researchCoordinatorAgent.generate(\n   157→      [{ role: 'user', content: `Create a research plan for: ${query}` }],\n   158→      { \n   159→        experimental_output: z.object({\n   160→          initialQueries: z.array(z.string()),\n   161→          qualityCriteria: z.array(z.string()),\n   162→          expectedDepth: z.string()\n   163→        })\n   164→      }\n   165→    );\n   166→    \n   167→    if (isAborted) {\n   168→      yield {\n   169→        type: ResearchEventType.ERROR_OCCURRED,\n   170→        timestamp: new Date().toISOString(),\n   171→        data: { error: 'Research aborted by user' }\n   172→      };\n   173→      return;\n   174→    }\n   175→    \n   176→    // Step 2: TRUE PARALLEL EXECUTION with semantic synthesis\n   177→    const researchTasks = researchPlan.object.initialQueries\n   178→      .slice(0, parallelAgents)\n   179→      .map((subQuery, index) => ({\n   180→        agentId: `Research Agent ${index + 1}`,\n   181→        query: subQuery,\n   182→        index\n   183→      }));\n   184→    \n   185→    // Track active agents and completion\n   186→    const activeAgents = new Set<string>();\n   187→    const completedAgents = new Set<string>();\n   188→    let totalInsightsProcessed = 0;\n   189→    let lastProgressReportTime = Date.now();\n   190→    \n   191→    // Launch agents truly in parallel without blocking\n   192→    for (const task of researchTasks) {\n   193→      activeAgents.add(task.agentId);\n   194→      \n   195→      // Emit activation event immediately\n   196→      yield {\n   197→        type: ResearchEventType.AGENT_ACTIVATED,\n   198→        timestamp: new Date().toISOString(),\n   199→        agentName: task.agentId,\n   200→        data: { query: task.query }\n   201→      };\n   202→      \n   203→      // Launch agent asynchronously - don't await!\n   204→      (async () => {\n   205→        try {\n   206→          // Step 1: Execute research with research agent\n   207→          const researchResult = await researchAgent.generate(\n   208→            [{\n   209→              role: 'user',\n   210→              content: `Research this specific aspect: \"${task.query}\"\n   211→              \n   212→              Use the two-phase process:\n   213→              Phase 1: Search for 2-3 initial queries about this topic\n   214→              Phase 2: Search for follow-up questions from the learnings (then STOP)\n   215→              \n   216→              Return findings as learnings with follow-up questions.`\n   217→            }],\n   218→            {\n   219→              maxSteps: 10,\n   220→            }\n   221→          );\n   222→          \n   223→          if (isAborted) return;\n   224→          \n   225→          // Step 2: Use webSummarizationAgent to compress content if needed\n   226→          let summarizedContent = researchResult.text;\n   227→          if (researchResult.text && researchResult.text.length > 5000) {\n   228→            eventQueue.push({\n   229→              type: ResearchEventType.AGENT_ACTIVATED,\n   230→              timestamp: new Date().toISOString(),\n   231→              agentName: 'Web Summarization Agent',\n   232→              data: { action: 'Compressing research content' }\n   233→            });\n   234→            \n   235→            const summarizationResult = await webSummarizationAgent.generate(\n   236→              [{\n   237→                role: 'user',\n   238→                content: `Summarize this research content while preserving all key insights and findings: ${researchResult.text}`\n   239→              }],\n   240→              {\n   241→                experimental_output: z.object({\n   242→                  summary: z.string(),\n   243→                  keyPoints: z.array(z.string()),\n   244→                  preservedInsights: z.number()\n   245→                })\n   246→              }\n   247→            );\n   248→            \n   249→            if (summarizationResult.object) {\n   250→              summarizedContent = summarizationResult.object.summary;\n   251→              eventQueue.push({\n   252→                type: ResearchEventType.WEB_SUMMARIZED,\n   253→                timestamp: new Date().toISOString(),\n   254→                agentName: task.agentId,\n   255→                data: {\n   256→                  originalLength: researchResult.text.length,\n   257→                  summarizedLength: summarizedContent.length,\n   258→                  keyPointsCount: summarizationResult.object.keyPoints.length\n   259→                }\n   260→              });\n   261→            }\n   262→          }\n   263→          \n   264→          // Step 3: Use learningExtractionAgent for structured extraction\n   265→          const learningResult = await learningExtractionAgent.generate(\n   266→            [{\n   267→              role: 'user',\n   268→              content: `Extract structured learnings from this research: ${summarizedContent}`\n   269→            }],\n   270→            {\n   271→              experimental_output: z.object({\n   272→                learnings: z.array(z.object({\n   273→                  learning: z.string(),\n   274→                  confidence: z.number(),\n   275→                  followUpQuestions: z.array(z.string()),\n   276→                  relevance: z.enum(['high', 'medium', 'low'])\n   277→                }))\n   278→              })\n   279→            }\n   280→          );\n   281→          \n   282→          if (isAborted) return;\n   283→          \n   284→          // Step 4: Use evaluationAgent to assess relevance\n   285→          if (learningResult.object && learningResult.object.learnings.length > 0) {\n   286→            const evaluationResult = await evaluationAgent.generate(\n   287→              [{\n   288→                role: 'user',\n   289→                content: `Evaluate the relevance of these learnings to the original query \"${query}\": ${JSON.stringify(learningResult.object.learnings)}`\n   290→              }],\n   291→              {\n   292→                experimental_output: z.object({\n   293→                  evaluatedLearnings: z.array(z.object({\n   294→                    learning: z.string(),\n   295→                    relevanceScore: z.number(),\n   296→                    keepForProcessing: z.boolean()\n   297→                  }))\n   298→                })\n   299→              }\n   300→            );\n   301→            \n   302→            eventQueue.push({\n   303→              type: ResearchEventType.EVALUATION_PERFORMED,\n   304→              timestamp: new Date().toISOString(),\n   305→              agentName: task.agentId,\n   306→              data: {\n   307→                totalLearnings: learningResult.object.learnings.length,\n   308→                relevantLearnings: evaluationResult.object?.evaluatedLearnings.filter(l => l.keepForProcessing).length || 0\n   309→              }\n   310→            });\n   311→            \n   312→            // Process only relevant learnings\n   313→            const relevantLearnings = evaluationResult.object?.evaluatedLearnings.filter(l => l.keepForProcessing) || [];\n   314→            \n   315→            for (const evaluatedLearning of relevantLearnings) {\n   316→              if (isAborted) break;\n   317→              \n   318→              totalInsightsProcessed++;\n   319→              console.log(`📝 [${task.agentId}] Processing learning ${totalInsightsProcessed}: \"${evaluatedLearning.learning.substring(0, 60)}...\"`);\n   320→              \n   321→              // Find original learning for follow-up questions\n   322→              const originalLearning = learningResult.object.learnings.find(l => \n   323→                l.learning === evaluatedLearning.learning\n   324→              );\n   325→              \n   326→              // Add to streaming knowledge graph for real-time processing\n   327→              await streamingGraph.addInsight({\n   328→                insight: evaluatedLearning.learning,\n   329→                source: task.query,\n   330→                confidence: evaluatedLearning.relevanceScore / 100,\n   331→                followUpQuestions: originalLearning?.followUpQuestions || []\n   332→              });\n   333→              \n   334→              // Get current graph state for event\n   335→              const graphState = await streamingGraph.getCurrentGraph();\n   336→              \n   337→              // Push learning event\n   338→              eventQueue.push({\n   339→                type: ResearchEventType.LEARNING_EXTRACTED,\n   340→                timestamp: new Date().toISOString(),\n   341→                agentName: task.agentId,\n   342→                data: {\n   343→                  learning: evaluatedLearning.learning,\n   344→                  source: task.query,\n   345→                  followUpQuestions: originalLearning?.followUpQuestions || [],\n   346→                  confidence: originalLearning?.confidence || 0.8,\n   347→                  relevanceScore: evaluatedLearning.relevanceScore,\n   348→                  insightNumber: totalInsightsProcessed,\n   349→                  graphMetrics: {\n   350→                    totalNodes: graphState.metadata.totalNodes,\n   351→                    totalRelationships: graphState.metadata.totalRelationships,\n   352→                    contradictions: graphState.contradictions.length,\n   353→                    gaps: graphState.gaps.length\n   354→                  }\n   355→                }\n   356→              });\n   357→              \n   358→              // Also emit as insight for backward compatibility\n   359→              eventQueue.push({\n   360→                type: ResearchEventType.INSIGHT_DISCOVERED,\n   361→                timestamp: new Date().toISOString(),\n   362→                agentName: task.agentId,\n   363→                data: {\n   364→                  insight: evaluatedLearning.learning,\n   365→                  source: task.query,\n   366→                  followUpQuestions: originalLearning?.followUpQuestions || [],\n   367→                  insightNumber: totalInsightsProcessed,\n   368→                  graphMetrics: {\n   369→                    totalNodes: graphState.metadata.totalNodes,\n   370→                    totalRelationships: graphState.metadata.totalRelationships,\n   371→                    contradictions: graphState.contradictions.length,\n   372→                    gaps: graphState.gaps.length\n   373→                  }\n   374→                },\n   375→                confidence: evaluatedLearning.relevanceScore / 100\n   376→              });\n   377→              \n   378→              // Notify that new events are available\n   379→              if (eventQueueResolver) {\n   380→                eventQueueResolver();\n   381→                eventQueueResolver = null;\n   382→              }\n   383→            }\n   384→          }\n   385→        } catch (error: any) {\n   386→          eventQueue.push({\n   387→            type: ResearchEventType.ERROR_OCCURRED,\n   388→            timestamp: new Date().toISOString(),\n   389→            agentName: task.agentId,\n   390→            data: { error: `Agent ${task.agentId} failed: ${error.message}` }\n   391→          });\n   392→        } finally {\n   393→          activeAgents.delete(task.agentId);\n   394→          completedAgents.add(task.agentId);\n   395→        }\n   396→      })(); // Execute immediately without blocking\n   397→    }\n   398→    \n   399→    // Stream events as they arrive - truly non-blocking\n   400→    const maxWaitTime = 600000; // 10 minutes for deep research\n   401→    const startTime = Date.now();\n   402→    \n   403→    while ((activeAgents.size > 0 || eventQueue.length > 0) && !isAborted) {\n   404→      // Yield any queued events immediately\n   405→      while (eventQueue.length > 0) {\n   406→        yield eventQueue.shift()!;\n   407→      }\n   408→      \n   409→      // Generate progressive report if enabled and enough time has passed\n   410→      if (progressiveReports && Date.now() - lastProgressReportTime > 5000) {\n   411→        const graphState = await streamingGraph.getCurrentGraph();\n   412→        const assessment = await streamingGraph.assessCompleteness(query);\n   413→        \n   414→        if (graphState.metadata.totalNodes > 0) {\n   415→          lastProgressReportTime = Date.now();\n   416→          \n   417→          yield {\n   418→            type: ResearchEventType.GRAPH_UPDATED,\n   419→            timestamp: new Date().toISOString(),\n   420→            data: {\n   421→              nodes: graphState.metadata.totalNodes,\n   422→              relationships: graphState.metadata.totalRelationships,\n   423→              coherence: assessment.coherence,\n   424→              completeness: assessment.completeness,\n   425→              depth: assessment.depth,\n   426→              overallQuality: assessment.overallQuality,\n   427→              contradictions: graphState.contradictions.length,\n   428→              gaps: graphState.gaps.length\n   429→            },\n   430→            confidence: assessment.overallQuality / 100\n   431→          };\n   432→        }\n   433→      }\n   434→      \n   435→      // Check for timeout\n   436→      if (Date.now() - startTime > maxWaitTime) {\n   437→        yield {\n   438→          type: ResearchEventType.ERROR_OCCURRED,\n   439→          timestamp: new Date().toISOString(),\n   440→          data: { error: 'Research timeout after 10 minutes' }\n   441→        };\n   442→        break;\n   443→      }\n   444→      \n   445→      // Wait for new events or timeout\n   446→      await Promise.race([\n   447→        new Promise<void>(resolve => {\n   448→          eventQueueResolver = resolve;\n   449→          // Also resolve after a short timeout to check other conditions\n   450→          setTimeout(resolve, 100);\n   451→        }),\n   452→        new Promise(resolve => setTimeout(resolve, 100))\n   453→      ]);\n   454→    }\n   455→    \n   456→    // Step 3: Get the final knowledge graph from streaming agent\n   457→    // The graph has been built incrementally during streaming\n   458→    knowledgeGraph = await streamingGraph.getCurrentGraph();\n   459→    \n   460→    // Emit final graph state\n   461→    if (knowledgeGraph && knowledgeGraph.metadata.totalNodes > 0) {\n   462→      yield {\n   463→        type: ResearchEventType.GRAPH_UPDATED,\n   464→        timestamp: new Date().toISOString(),\n   465→        data: {\n   466→          nodes: knowledgeGraph.metadata.totalNodes,\n   467→          relationships: knowledgeGraph.metadata.totalRelationships,\n   468→          contradictions: knowledgeGraph.contradictions.length,\n   469→          gaps: knowledgeGraph.gaps.length,\n   470→          message: 'Final knowledge graph state'\n   471→        }\n   472→      };\n   473→      \n   474→      // Ensure final state is persisted to Neo4j\n   475→      await neo4jStorage.storeGraph(knowledgeGraph).catch(err => {\n   476→        console.error(`Final Neo4j store failed: ${err.message}`);\n   477→      });\n   478→    }\n   479→    \n   480→    // Step 4: Continuous quality assessment with streaming\n   481→    while (iterationCount < maxIterations && currentQualityScore < qualityThreshold) {\n   482→      // Get current graph state for assessment\n   483→      const currentGraphState = await streamingGraph.getCurrentGraph();\n   484→      const collectedInsights = currentGraphState.insights || [];\n   485→      \n   486→      // Assess quality with actual content\n   487→      const qualityResult = await qualityAssessmentAgent.generate(\n   488→        [{ \n   489→          role: 'user', \n   490→          content: `Assess the quality of research on \"${query}\" based on:\n   491→          \n   492→          Knowledge Graph Statistics:\n   493→          - Nodes: ${currentGraphState.metadata?.totalNodes || 0}\n   494→          - Relationships: ${currentGraphState.metadata?.totalRelationships || 0}\n   495→          - Insights collected: ${collectedInsights.length}\n   496→          \n   497→          Sample Insights:\n   498→          ${collectedInsights.slice(0, 5).map(i => `- ${i.insight}`).join('\\n')}\n   499→          \n   500→          Evaluate completeness (coverage of topic), coherence (logical connections), depth (detail level), and overall quality.\n   501→          Return scores from 0-100 for each metric.` \n   502→        }],\n   503→        {\n   504→          experimental_output: z.object({\n   505→            completeness: z.number(),\n   506→            coherence: z.number(),\n   507→            depth: z.number(),\n   508→            overallQuality: z.number()\n   509→          })\n   510→        }\n   511→      );\n   512→      \n   513→      currentQualityScore = qualityResult.object.overallQuality;\n   514→      \n   515→      yield {\n   516→        type: ResearchEventType.QUALITY_ASSESSED,\n   517→        timestamp: new Date().toISOString(),\n   518→        data: {\n   519→          scores: qualityResult.object,\n   520→          iteration: iterationCount + 1\n   521→        },\n   522→        confidence: currentQualityScore / 100\n   523→      };\n   524→      \n   525→      // Check if we should continue\n   526→      if (currentQualityScore >= qualityThreshold) {\n   527→        break;\n   528→      }\n   529→      \n   530→      // Step 5: Parallel refinement if needed\n   531→      if (iterationCount < maxIterations - 1) {\n   532→        const gaps = knowledgeGraph?.gaps || [];\n   533→        \n   534→        // Add defensive check to ensure gaps are related to the original query\n   535→        const relevantGaps = gaps.filter(gap => {\n   536→          // Check if the gap is actually related to the original query\n   537→          const queryLower = query.toLowerCase();\n   538→          const gapLower = gap.area.toLowerCase();\n   539→          const suggestedQueriesLower = gap.suggestedQueries.map(q => q.toLowerCase());\n   540→          \n   541→          // Simple relevance check - at least one query term should appear in the gap or its queries\n   542→          const queryTerms = queryLower.split(/[\\s,;]+/).filter(t => t.length > 3);\n   543→          const isRelevant = queryTerms.some(term => \n   544→            gapLower.includes(term) || \n   545→            suggestedQueriesLower.some(q => q.includes(term))\n   546→          );\n   547→          \n   548→          if (!isRelevant) {\n   549→            console.log(`⚠️ Filtering out unrelated gap: \"${gap.area}\"`);\n   550→          }\n   551→          \n   552→          return isRelevant && (gap.importance === 'critical' || gap.importance === 'high');\n   553→        });\n   554→        \n   555→        const refinementQueries = relevantGaps\n   556→          .slice(0, parallelAgents)\n   557→          .flatMap(gap => gap.suggestedQueries);\n   558→        \n   559→        if (refinementQueries.length > 0) {\n   560→          // Execute parallel refinement\n   561→          const refinementPromises = refinementQueries.map(async (query, index) => {\n   562→            const agentName = `Refinement Agent ${index + 1}`;\n   563→            \n   564→            // Emit activation event before starting\n   565→            console.log(`Activating ${agentName} for query: ${query}`);\n   566→            \n   567→            return {\n   568→              agentName,\n   569→              query,\n   570→              result: await researchAgent.generate(\n   571→                [{ role: 'user', content: `Refine research: ${query}` }],\n   572→                { maxSteps: 5 }\n   573→              )\n   574→            };\n   575→          });\n   576→          \n   577→          const refinementResults = await Promise.all(refinementPromises);\n   578→          \n   579→          // Emit activation events and update graph with refinements\n   580→          for (const refinement of refinementResults) {\n   581→            // Emit activation event\n   582→            yield {\n   583→              type: ResearchEventType.AGENT_ACTIVATED,\n   584→              timestamp: new Date().toISOString(),\n   585→              agentName: refinement.agentName,\n   586→              data: { query: refinement.query }\n   587→            };\n   588→            \n   589→            if (refinement.result.object) {\n   590→              knowledgeGraph = await buildKnowledgeGraph(refinement.result.object, knowledgeGraph, query);\n   591→              \n   592→              yield {\n   593→                type: ResearchEventType.GRAPH_UPDATED,\n   594→                timestamp: new Date().toISOString(),\n   595→                data: {\n   596→                  nodes: knowledgeGraph.nodes.length,\n   597→                  relationships: knowledgeGraph.relationships.length,\n   598→                  refinementApplied: true\n   599→                }\n   600→              };\n   601→            }\n   602→          }\n   603→        }\n   604→      }\n   605→      \n   606→      iterationCount++;\n   607→      \n   608→      yield {\n   609→        type: ResearchEventType.ITERATION_COMPLETE,\n   610→        timestamp: new Date().toISOString(),\n   611→        data: {\n   612→          iteration: iterationCount,\n   613→          qualityScore: currentQualityScore,\n   614→          continueRefining: iterationCount < maxIterations\n   615→        }\n   616→      };\n   617→    }\n   618→    \n   619→    // Generate final comprehensive report with knowledge graph insights\n   620→    const finalAssessment = await streamingGraph.assessCompleteness(query);\n   621→    \n   622→    // Generate rich final report using report agent with graph insights\n   623→    let finalReport = '';\n   624→    if (knowledgeGraph && knowledgeGraph.metadata.totalNodes > 0) {\n   625→      try {\n   626→        // Ensure we have actual insights to report on\n   627→        const actualInsights = knowledgeGraph.insights || [];\n   628→        const insightTexts = actualInsights.map(i => i.insight || i).filter(Boolean);\n   629→        \n   630→        const reportResult = await reportAgent.generate(\n   631→          [{\n   632→            role: 'user',\n   633→            content: `Generate a comprehensive research report for the query: \"${query}\"\n   634→            \n   635→            ACTUAL RESEARCH FINDINGS (USE ONLY THESE - DO NOT HALLUCINATE):\n   636→            ${insightTexts.map((insight, idx) => `${idx + 1}. ${insight}`).join('\\n')}\n   637→            \n   638→            Knowledge Graph Metrics:\n   639→            - Total Entities: ${knowledgeGraph.metadata.totalNodes}\n   640→            - Total Relationships: ${knowledgeGraph.metadata.totalRelationships}\n   641→            - Research Completeness: ${finalAssessment.completeness.toFixed(1)}%\n   642→            - Information Coherence: ${finalAssessment.coherence.toFixed(1)}%\n   643→            - Analysis Depth: ${finalAssessment.depth.toFixed(1)}%\n   644→            - Overall Quality Score: ${finalAssessment.overallQuality.toFixed(1)}%\n   645→            \n   646→            ${knowledgeGraph.contradictions.length > 0 ? `Contradictions Found: ${knowledgeGraph.contradictions.length}` : 'No contradictions detected'}\n   647→            ${knowledgeGraph.gaps.length > 0 ? `Knowledge Gaps Identified: ${knowledgeGraph.gaps.map(g => g.area).join(', ')}` : ''}\n   648→            \n   649→            Instructions:\n   650→            1. Synthesize ONLY the provided insights above\n   651→            2. DO NOT add information not present in the insights\n   652→            3. Structure the report with clear sections\n   653→            4. Highlight key findings and their implications\n   654→            5. Maintain factual accuracy based on the collected data`\n   655→          }],\n   656→          { maxSteps: 3 }\n   657→        );\n   658→        \n   659→        if (reportResult.text) {\n   660→          finalReport = reportResult.text;\n   661→        }\n   662→      } catch (error) {\n   663→        console.error('Report generation error:', error);\n   664→        finalReport = `Research Report for: ${query}\\n\\nKey Findings:\\n${knowledgeGraph.insights.slice(0, 10).map(i => `- ${i.insight}`).join('\\n')}\\n\\nNote: Full report generation encountered an error.`;\n   665→      }\n   666→    }\n   667→    \n   668→    // Final event with knowledge graph data\n   669→    yield {\n   670→      type: ResearchEventType.RESEARCH_COMPLETE,\n   671→      timestamp: new Date().toISOString(),\n   672→      data: {\n   673→        finalQualityScore: currentQualityScore || finalAssessment.overallQuality,\n   674→        totalIterations: iterationCount,\n   675→        totalInsights: totalInsightsProcessed,\n   676→        graphSize: {\n   677→          nodes: knowledgeGraph?.metadata.totalNodes || 0,\n   678→          relationships: knowledgeGraph?.metadata.totalRelationships || 0\n   679→        },\n   680→        knowledgeGraphMetrics: {\n   681→          completeness: finalAssessment.completeness,\n   682→          coherence: finalAssessment.coherence,\n   683→          depth: finalAssessment.depth,\n   684→          contradictions: knowledgeGraph?.contradictions.length || 0,\n   685→          gaps: knowledgeGraph?.gaps.length || 0\n   686→        },\n   687→        insights: knowledgeGraph?.insights || [],\n   688→        report: finalReport\n   689→      }\n   690→    };\n   691→    \n   692→  } catch (error: any) {\n   693→    yield {\n   694→      type: ResearchEventType.ERROR_OCCURRED,\n   695→      timestamp: new Date().toISOString(),\n   696→      data: {\n   697→        error: error.message,\n   698→        stack: error.stack\n   699→      }\n   700→    };\n   701→  }\n   702→}\n   703→\n   704→// Helper function to consume the stream with a callback\n   705→export async function streamResearchWithCallback(\n   706→  query: string,\n   707→  onEvent: (event: ResearchEvent) => void,\n   708→  options?: {\n   709→    maxIterations?: number;\n   710→    qualityThreshold?: number;\n   711→    parallelAgents?: number;\n   712→    abortSignal?: AbortSignal;\n   713→  }\n   714→): Promise<void> {\n   715→  const stream = executeStreamingResearch(query, options);\n   716→  \n   717→  for await (const event of stream) {\n   718→    onEvent(event);\n   719→  }\n   720→}\n   721→\n   722→// Helper function to collect all events into an array\n   723→export async function collectResearchEvents(\n   724→  query: string,\n   725→  options?: {\n   726→    maxIterations?: number;\n   727→    qualityThreshold?: number;\n   728→    parallelAgents?: number;\n   729→    abortSignal?: AbortSignal;\n   730→  }\n   731→): Promise<ResearchEvent[]> {\n   732→  const events: ResearchEvent[] = [];\n   733→  const stream = executeStreamingResearch(query, options);\n   734→  \n   735→  for await (const event of stream) {\n   736→    events.push(event);\n   737→  }\n   738→  \n   739→  return events;\n   740→}\n   741→\n   742→// Backward compatibility wrapper for synchronous execution\n   743→export async function executeStreamingResearchSync(\n   744→  query: string,\n   745→  options?: {\n   746→    maxIterations?: number;\n   747→    qualityThreshold?: number;\n   748→    parallelAgents?: number;\n   749→  }\n   750→): Promise<{\n   751→  success: boolean;\n   752→  researchData: any;\n   753→  qualityScore: number;\n   754→  iterations: number;\n   755→  report?: string;\n   756→  knowledgeGraph?: KnowledgeGraph;\n   757→  insights: any[];\n   758→}> {\n   759→  const events = await collectResearchEvents(query, options);\n   760→  \n   761→  // Synthesize events into traditional result format\n   762→  let finalQualityScore = 0;\n   763→  let totalIterations = 0;\n   764→  let knowledgeGraph: KnowledgeGraph | null = null;\n   765→  const insights: any[] = [];\n   766→  const researchData: any = { queries: [], searchResults: [], learnings: [] };\n   767→  \n   768→  for (const event of events) {\n   769→    switch (event.type) {\n   770→      case ResearchEventType.INSIGHT_DISCOVERED:\n   771→        insights.push(event.data);\n   772→        if (event.data.insight) {\n   773→          researchData.learnings.push({\n   774→            learning: event.data.insight,\n   775→            source: event.data.source,\n   776→            followUpQuestions: event.data.followUpQuestions || []\n   777→          });\n   778→        }\n   779→        break;\n   780→      case ResearchEventType.QUALITY_ASSESSED:\n   781→        finalQualityScore = event.data.scores?.overallQuality || finalQualityScore;\n   782→        break;\n   783→      case ResearchEventType.ITERATION_COMPLETE:\n   784→        totalIterations = event.data.iteration;\n   785→        break;\n   786→      case ResearchEventType.RESEARCH_COMPLETE:\n   787→        finalQualityScore = event.data.finalQualityScore || finalQualityScore;\n   788→        totalIterations = event.data.totalIterations || totalIterations;\n   789→        if (event.data.insights) {\n   790→          insights.push(...event.data.insights);\n   791→        }\n   792→        break;\n   793→      case ResearchEventType.GRAPH_UPDATED:\n   794→        // Track the latest graph state\n   795→        if (event.data) {\n   796→          knowledgeGraph = {\n   797→            nodes: new Array(event.data.nodes).fill({}),\n   798→            relationships: new Array(event.data.relationships).fill({}),\n   799→            insights: event.data.newInsights ? new Array(event.data.newInsights).fill({}) : [],\n   800→            contradictions: [],\n   801→            gaps: [],\n   802→            metadata: {\n   803→              createdAt: new Date().toISOString(),\n   804→              lastUpdated: new Date().toISOString(),\n   805→              version: '1.0',\n   806→              source: 'streaming-research'\n   807→            }\n   808→          } as KnowledgeGraph;\n   809→        }\n   810→        break;\n   811→    }\n   812→  }\n   813→  \n   814→  // Generate report from insights\n   815→  const report = insights.length > 0 \n   816→    ? `Research Report\\n\\nKey Insights:\\n${insights.map(i => `- ${i.insight || i}`).join('\\n')}\\n\\nTotal iterations: ${totalIterations}\\nFinal quality score: ${finalQualityScore}`\n   817→    : undefined;\n   818→  \n   819→  return {\n   820→    success: finalQualityScore >= 60,\n   821→    researchData,\n   822→    qualityScore: finalQualityScore,\n   823→    iterations: totalIterations,\n   824→    report,\n   825→    knowledgeGraph: knowledgeGraph || undefined,\n   826→    insights\n   827→  };\n   828→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "text",
        "text": "Now let me read the other key files mentioned in the task to understand the complete pipeline:"
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01EjMbNUMLumYJgs1b7T5QSB",
        "name": "Read",
        "input": {
          "file_path": "/mnt/c/Users/caleb/Desktop/GithubProjects/deepfield/src/mastra/agents/researchAgent.ts"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01WmmfTS3rJd3jXDP1DcGaUC",
        "name": "Read",
        "input": {
          "file_path": "/mnt/c/Users/caleb/Desktop/GithubProjects/deepfield/src/mastra/agents/reportAgent.ts"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01G9xCBjHQvF9P1WXqMhDux6",
        "name": "Read",
        "input": {
          "file_path": "/mnt/c/Users/caleb/Desktop/GithubProjects/deepfield/src/mastra/agents/learningExtractionAgent.ts"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01HdpGH4VjmXaznbfdNv694J",
        "name": "Read",
        "input": {
          "file_path": "/mnt/c/Users/caleb/Desktop/GithubProjects/deepfield/src/mastra/storage/neo4jStorage.ts"
        }
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01EjMbNUMLumYJgs1b7T5QSB",
        "type": "tool_result",
        "content": "     1→import { openai } from '@ai-sdk/openai';\n     2→import { Agent } from '@mastra/core/agent';\n     3→import { evaluateResultTool } from '../tools/evaluateResultTool';\n     4→import { extractLearningsTool } from '../tools/extractLearningsTool';\n     5→import { webSearchTool } from '../tools/webSearchTool';\n     6→\n     7→const mainModel = openai('gpt-4.1-mini');\n     8→\n     9→export const researchAgent = new Agent({\n    10→  name: 'Research Agent',\n    11→  instructions: `You are an expert research agent. Your goal is to research topics thoroughly by following this EXACT process:\n    12→\n    13→  **PHASE 1: Initial Research**\n    14→  1. Break down the main topic into 2 specific, focused search queries\n    15→  2. For each query, use the webSearchTool to search the web\n    16→  3. Use evaluateResultTool to determine if results are relevant\n    17→  4. For relevant results, use extractLearningsTool to extract key learnings and follow-up questions\n    18→\n    19→  **PHASE 2: Follow-up Research**\n    20→  1. After completing Phase 1, collect ALL follow-up questions from the extracted learnings\n    21→  2. Search for each follow-up question using webSearchTool\n    22→  3. Use evaluateResultTool and extractLearningsTool on these follow-up results\n    23→  4. **STOP after Phase 2 - do NOT search additional follow-up questions from Phase 2 results**\n    24→\n    25→  **Important Guidelines:**\n    26→  - Keep search queries focused and specific - avoid overly general queries\n    27→  - Track all completed queries to avoid repetition\n    28→  - Only search follow-up questions from the FIRST round of learnings\n    29→  - Do NOT create infinite loops by searching follow-up questions from follow-up results\n    30→\n    31→  **Output Structure:**\n    32→  Return findings in JSON format with:\n    33→  - queries: Array of all search queries used (initial + follow-up)\n    34→  - searchResults: Array of relevant search results found\n    35→  - learnings: Array of key learnings extracted from results\n    36→  - completedQueries: Array tracking what has been searched\n    37→  - phase: Current phase of research (\"initial\" or \"follow-up\")\n    38→\n    39→  **Error Handling:**\n    40→  - If all searches fail, use your knowledge to provide basic information\n    41→  - Always complete the research process even if some searches fail\n    42→\n    43→  Use all the tools available to you systematically and stop after the follow-up phase.\n    44→  `,\n    45→  model: mainModel,\n    46→  tools: {\n    47→    webSearchTool,\n    48→    evaluateResultTool,\n    49→    extractLearningsTool,\n    50→  },\n    51→});\n    52→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01WmmfTS3rJd3jXDP1DcGaUC",
        "type": "tool_result",
        "content": "     1→import { Agent } from '@mastra/core/agent';\n     2→import { openai } from '@ai-sdk/openai';\n     3→\n     4→const reportModel = openai('gpt-4.1-mini');\n     5→\n     6→export const reportAgent = new Agent({\n     7→  name: 'Report Agent',\n     8→  instructions: `You are an expert researcher. Today is ${new Date().toISOString()}. Follow these instructions when responding:\n     9→  - You may be asked to research subjects that are after your knowledge cutoff, assume the user is right when presented with news.\n    10→  - The user is a highly experienced analyst, no need to simplify it, be as detailed as possible and make sure your response is correct.\n    11→  - Be highly organized.\n    12→  - Suggest solutions that I didn't think about.\n    13→  - Be proactive and anticipate my needs.\n    14→  - Treat me as an expert in all subject matter.\n    15→  - Mistakes erode my trust, so be accurate and thorough.\n    16→  - Provide detailed explanations, I'm comfortable with lots of detail.\n    17→  - Value good arguments over authorities, the source is irrelevant.\n    18→  - Consider new technologies and contrarian ideas, not just the conventional wisdom.\n    19→  - You may use high levels of speculation or prediction, just flag it for me.\n    20→  - Use Markdown formatting.\n    21→\n    22→  Your task is to generate comprehensive reports based on research data that includes:\n    23→  - Search queries used\n    24→  - Relevant search results\n    25→  - Key learnings extracted from those results\n    26→  - Follow-up questions identified\n    27→\n    28→  Structure your reports with clear sections, headings, and focus on synthesizing the information\n    29→  into a cohesive narrative rather than simply listing facts.`,\n    30→  model: reportModel,\n    31→});\n    32→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  }
]