[
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01AHkpM3966XAB5MrgLroF1b",
        "type": "tool_result",
        "content": "     1→import io\n     2→import logging\n     3→import re\n     4→from typing import Union, Optional, Dict, Any, List\n     5→import asyncio\n     6→\n     7→from fastapi import FastAPI, File, UploadFile, Form, HTTPException\n     8→from fastapi.middleware.cors import CORSMiddleware\n     9→from pydantic import BaseModel\n    10→\n    11→from .pdf import read_pdf\n    12→from .core.document_framework import DocumentGenerationFramework\n    13→from llama_index.core.schema import Document\n    14→\n    15→\n    16→def convert_section(text):\n    17→    match = re.fullmatch(r'section(\\d+)', text, re.IGNORECASE)\n    18→    if match:\n    19→        number = match.group(1)\n    20→        return f\"Section {number}\"\n    21→    else:\n    22→        raise ValueError(\"Input string does not match the pattern 'section[0-9]+'\")\n    23→\n    24→app = FastAPI()\n    25→\n    26→app.add_middleware(\n    27→    CORSMiddleware,\n    28→    allow_origins=[\"http://localhost:3000\"],  # Restricted to specific origins for security\n    29→    allow_credentials=True,\n    30→    allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"],\n    31→    allow_headers=[\"*\"],\n    32→)\n    33→\n    34→@app.get(\"/\")\n    35→def read_root():\n    36→    return {\"Hello\": \"World3\"}\n    37→\n    38→\n    39→@app.get(\"/items/{item_id}\")\n    40→def read_item(item_id: int, q: Union[str, None] = None):\n    41→    return {\"item_id\": item_id, \"q\": q}\n    42→\n    43→class DocumentGenerationRequest(BaseModel):\n    44→    \"\"\"Request model for document generation with explicit plugin selection.\"\"\"\n    45→    plugin_id: str  # Required - no default, user must specify\n    46→    template_id: Optional[str] = None\n    47→    parameters: Optional[Dict[str, Any]] = {}\n    48→\n    49→\n    50→class DocumentGenerationResponse(BaseModel):\n    51→    \"\"\"Unified response model for all document generation endpoints\"\"\"\n    52→    sections: List[str]  # List of section names\n    53→    texts: List[str]     # List of section texts (parallel to sections)\n    54→    metadata: Optional[Dict[str, Any]] = None\n    55→    error: Optional[str] = None\n    56→\n    57→\n    58→# Initialize framework for new endpoints\n    59→framework = DocumentGenerationFramework()\n    60→\n    61→\n    62→@app.post(\"/uploadfile/\")\n    63→async def create_upload_file(file: UploadFile):\n    64→    \"\"\"Unified endpoint using new framework for informed consent KI summary\"\"\"\n    65→    contents = await file.read()\n    66→    file_io = io.BytesIO(contents)\n    67→    pdf_pages = read_pdf(file_io)\n    68→    \n    69→    # Convert to Document\n    70→    full_text = \"\\n\\n\".join(pdf_pages.texts)\n    71→    document = Document(\n    72→        text=full_text,\n    73→        metadata={\n    74→            \"page_labels\": pdf_pages.labels,\n    75→            \"source\": file.filename or \"uploaded_file.pdf\"\n    76→        }\n    77→    )\n    78→    \n    79→    # Generate using framework with informed-consent-ki type\n    80→    result = await framework.generate(\n    81→        document_type=\"informed-consent-ki\",\n    82→        parameters={},\n    83→        document=document\n    84→    )\n    85→    \n    86→    if result.success:\n    87→        # Parse sections from content for compatibility\n    88→        sections = []\n    89→        texts = []\n    90→        \n    91→        if \"Section\" in result.content:\n    92→            section_parts = result.content.split(\"\\n\\nSection \")\n    93→            for i, part in enumerate(section_parts):\n    94→                if part.strip():\n    95→                    if i == 0 and not part.startswith(\"Section\"):\n    96→                        # Skip header if present\n    97→                        continue\n    98→                    lines = part.split(\"\\n\", 1)\n    99→                    if len(lines) > 0:\n   100→                        section_num = lines[0].strip() if i > 0 else part.split(\"\\n\")[0].replace(\"Section \", \"\").strip()\n   101→                        section_text = lines[1].strip() if len(lines) > 1 else \"\"\n   102→                        sections.append(f\"Section {section_num}\")\n   103→                        texts.append(section_text)\n   104→        \n   105→        # Add total summary\n   106→        sections.append(\"Total Summary\")\n   107→        texts.append(\"\\n\\n\".join(texts))\n   108→        \n   109→        return {\"sections\": sections, \"texts\": texts}\n   110→    else:\n   111→        # Return error in expected format\n   112→        return {\n   113→            \"sections\": [\"Error\"],\n   114→            \"texts\": [f\"Failed to generate summary: {result.error_message}\"]\n   115→        }\n   116→\n   117→\n   118→@app.post(\"/generate/\")\n   119→async def generate_document(\n   120→    file: UploadFile = File(...),\n   121→    plugin_id: str = Form(...),  # Required - user must explicitly specify\n   122→    template_id: Optional[str] = Form(None),\n   123→    parameters: Optional[str] = Form(\"{}\")\n   124→):\n   125→    \"\"\"\n   126→    Unified endpoint for document generation with explicit plugin selection.\n   127→    \n   128→    Args:\n   129→        file: The PDF file to process\n   130→        plugin_id: ID of the plugin to use (required - e.g., \"informed-consent-ki\", \"clinical-protocol\")\n   131→        template_id: Optional specific template ID within the plugin\n   132→        parameters: JSON string with additional parameters\n   133→    \n   134→    Returns:\n   135→        Standardized response with sections and texts lists\n   136→    \"\"\"\n   137→    try:\n   138→        # Parse parameters\n   139→        import json\n   140→        params = json.loads(parameters) if parameters else {}\n   141→        \n   142→        # Read PDF\n   143→        contents = await file.read()\n   144→        file_io = io.BytesIO(contents)\n   145→        pdf_pages = read_pdf(file_io)\n   146→        \n   147→        # Convert to Document\n   148→        full_text = \"\\n\\n\".join(pdf_pages.texts)\n   149→        document = Document(\n   150→            text=full_text,\n   151→            metadata={\n   152→                \"page_labels\": pdf_pages.labels,\n   153→                \"source\": file.filename\n   154→            }\n   155→        )\n   156→        \n   157→        # Add template_id to parameters if provided\n   158→        if template_id:\n   159→            params[\"template_id\"] = template_id\n   160→        \n   161→        # Generate using framework with explicit plugin\n   162→        result = await framework.generate(\n   163→            document_type=plugin_id,  # Using plugin_id as document_type\n   164→            parameters=params,\n   165→            document=document\n   166→        )\n   167→        \n   168→        if result.success:\n   169→            sections = []\n   170→            texts = []\n   171→            \n   172→            # Parse sections based on plugin type\n   173→            if plugin_id == \"informed-consent-ki\":\n   174→                # KI summary format with 9 sections\n   175→                if \"Section\" in result.content:\n   176→                    section_parts = result.content.split(\"\\n\\nSection \")\n   177→                    for i, part in enumerate(section_parts):\n   178→                        if part.strip():\n   179→                            if i == 0 and not part.startswith(\"Section\"):\n   180→                                continue\n   181→                            lines = part.split(\"\\n\", 1)\n   182→                            if len(lines) > 0:\n   183→                                section_num = lines[0].strip() if i > 0 else part.split(\"\\n\")[0].replace(\"Section \", \"\").strip()\n   184→                                section_text = lines[1].strip() if len(lines) > 1 else \"\"\n   185→                                sections.append(f\"Section {section_num}\")\n   186→                                texts.append(section_text)\n   187→                    \n   188→                    # Add total summary for KI\n   189→                    sections.append(\"Total Summary\")\n   190→                    texts.append(\"\\n\\n\".join(texts))\n   191→            else:\n   192→                # Generic parsing for other document types\n   193→                if \"\\n## \" in result.content:\n   194→                    # Parse markdown sections\n   195→                    content_sections = result.content.split(\"\\n## \")\n   196→                    for i, section in enumerate(content_sections):\n   197→                        if section.strip():\n   198→                            lines = section.split(\"\\n\", 1)\n   199→                            if len(lines) > 0:\n   200→                                section_title = lines[0].strip()\n   201→                                section_content = lines[1].strip() if len(lines) > 1 else \"\"\n   202→                                sections.append(section_title)\n   203→                                texts.append(section_content)\n   204→                else:\n   205→                    # Return as single section\n   206→                    sections.append(document_type.replace(\"-\", \" \").title())\n   207→                    texts.append(result.content)\n   208→            \n   209→            return {\n   210→                \"sections\": sections,\n   211→                \"texts\": texts,\n   212→                \"metadata\": result.metadata\n   213→            }\n   214→        else:\n   215→            return {\n   216→                \"sections\": [\"Error\"],\n   217→                \"texts\": [f\"Failed to generate document: {result.error_message}\"],\n   218→                \"error\": result.error_message\n   219→            }\n   220→            \n   221→    except Exception as e:\n   222→        return {\n   223→            \"sections\": [\"Error\"],\n   224→            \"texts\": [str(e)],\n   225→            \"error\": str(e)\n   226→        }\n   227→\n   228→\n   229→@app.get(\"/plugins/\")\n   230→async def list_plugins():\n   231→    \"\"\"List all available plugins for document processing.\n   232→    \n   233→    Returns a list of plugins with their IDs, names, and descriptions.\n   234→    Users must specify one of these plugin IDs when calling /generate/.\n   235→    \"\"\"\n   236→    plugin_ids = framework.list_supported_document_types()\n   237→    return {\n   238→        \"plugins\": [\n   239→            {\n   240→                \"plugin_id\": plugin_id,\n   241→                \"info\": framework.get_plugin_info(plugin_id)\n   242→            }\n   243→            for plugin_id in plugin_ids\n   244→        ],\n   245→        \"total\": len(plugin_ids)\n   246→    }\n   247→\n   248→\n   249→@app.get(\"/plugins/{plugin_id}/\")\n   250→async def get_plugin_info(plugin_id: str):\n   251→    \"\"\"Get detailed information about a specific plugin.\n   252→    \n   253→    Args:\n   254→        plugin_id: The ID of the plugin (e.g., \"informed-consent-ki\")\n   255→    \n   256→    Returns:\n   257→        Detailed plugin information including supported templates,\n   258→        validation rules, and capabilities.\n   259→    \"\"\"\n   260→    info = framework.get_plugin_info(plugin_id)\n   261→    if not info:\n   262→        raise HTTPException(\n   263→            status_code=404, \n   264→            detail=f\"Plugin '{plugin_id}' not found. Use GET /plugins/ to see available plugins.\"\n   265→        )\n   266→    return {\n   267→        \"plugin_id\": plugin_id,\n   268→        \"details\": info,\n   269→        \"usage\": {\n   270→            \"endpoint\": \"/generate/\",\n   271→            \"required_fields\": {\n   272→                \"file\": \"PDF file to process\",\n   273→                \"plugin_id\": plugin_id,\n   274→                \"template_id\": \"Optional template within plugin\",\n   275→                \"parameters\": \"Optional JSON parameters\"\n   276→            }\n   277→        }\n   278→    }\n   279→\n   280→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01YPzcpR4T5mKhxwFZYVSN8c",
        "type": "tool_result",
        "content": "     1→\"\"\"\n     2→Configuration settings for the IRB KI Summary application.\n     3→Centralizes all hardcoded values for easier maintenance.\n     4→\"\"\"\n     5→\n     6→import os\n     7→from pathlib import Path\n     8→from typing import Dict, Any\n     9→\n    10→# Base paths\n    11→BASE_DIR = Path(__file__).parent.parent\n    12→APP_DIR = BASE_DIR / \"app\"\n    13→TEST_DATA_DIR = BASE_DIR / \"test_data\"\n    14→\n    15→# Memory system configuration\n    16→MEMORY_CONFIG = {\n    17→    \"max_entities\": 5000,\n    18→    \"max_episodes\": 1000,\n    19→    \"max_observations_per_entity\": 100,\n    20→    \"max_memory_size_mb\": 10,\n    21→    \"decay_lambda\": 0.1,\n    22→    \"decay_enabled\": True,\n    23→    \"confidence_threshold\": 0.5,\n    24→    \"relevance_threshold\": 0.3,\n    25→}\n    26→\n    27→# Token and text processing limits\n    28→TEXT_PROCESSING = {\n    29→    \"max_tokens_per_batch\": 18000,\n    30→    \"truncation_limits\": {\n    31→        \"short\": 150,\n    32→        \"medium\": 200,\n    33→        \"long\": 4000,\n    34→        \"extra_long\": 8000\n    35→    },\n    36→    \"chunk_size\": 2000,  # Default chunk size for text processing\n    37→}\n    38→\n    39→# Test data configuration\n    40→TEST_CONFIG = {\n    41→    \"default_test_pdf\": \"HUM00173014.pdf\",\n    42→    \"test_data_path\": str(TEST_DATA_DIR),\n    43→    \"consistency_test_runs\": 3,\n    44→    \"cv_target_threshold\": 15.0,  # Coefficient of variation target < 15%\n    45→}\n    46→\n    47→# Azure OpenAI configuration\n    48→AZURE_OPENAI_CONFIG = {\n    49→    \"temperature\": 0,\n    50→    \"top_p\": 0.0,\n    51→    \"default_headers\": {\n    52→        \"OpenAI-Organization\": \"231173\",\n    53→        \"Shortcode\": \"231173\"\n    54→    },\n    55→    \"llm_model\": \"gpt-4o\",\n    56→    \"embedding_model\": \"text-embedding-3-large\",\n    57→}\n    58→\n    59→# CORS configuration\n    60→CORS_CONFIG = {\n    61→    \"allow_origins\": os.getenv(\"CORS_ORIGINS\", \"http://localhost:3000\").split(\",\"),\n    62→    \"allow_credentials\": True,\n    63→    \"allow_methods\": [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"],\n    64→    \"allow_headers\": [\"*\"],\n    65→}\n    66→\n    67→# Validation constants\n    68→VALIDATION_CONFIG = {\n    69→    \"prohibited_phrases\": [\n    70→        \"[INSERT\", \"TODO\", \"TBD\", \"PLACEHOLDER\",\n    71→        \"[EXTRACTED\", \"[YOUR\", \"[COMPANY\", \n    72→        \"{{\", \"}}\", \"{%\", \"%}\"\n    73→    ],\n    74→    \"critical_value_patterns\": [\n    75→        r\"\\d+\\s*(?:days?|weeks?|months?|years?)\",\n    76→        r\"\\$[\\d,]+(?:\\.\\d{2})?\",\n    77→        r\"\\d+\\s*(?:mg|ml|mcg|units?)\",\n    78→        r\"\\d+:\\d+\\s*(?:am|pm|AM|PM)\",\n    79→    ],\n    80→}\n    81→\n    82→# API rate limiting\n    83→RATE_LIMIT_CONFIG = {\n    84→    \"requests_per_minute\": 60,\n    85→    \"requests_per_hour\": 1000,\n    86→    \"burst_size\": 10,\n    87→}\n    88→\n    89→# Logging configuration\n    90→LOGGING_CONFIG = {\n    91→    \"level\": os.getenv(\"LOG_LEVEL\", \"INFO\"),\n    92→    \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    93→    \"file\": \"app.log\",\n    94→    \"max_bytes\": 10485760,  # 10MB\n    95→    \"backup_count\": 5,\n    96→}\n    97→\n    98→def get_config() -> Dict[str, Any]:\n    99→    \"\"\"Get complete configuration dictionary.\"\"\"\n   100→    return {\n   101→        \"memory\": MEMORY_CONFIG,\n   102→        \"text_processing\": TEXT_PROCESSING,\n   103→        \"test\": TEST_CONFIG,\n   104→        \"azure_openai\": AZURE_OPENAI_CONFIG,\n   105→        \"cors\": CORS_CONFIG,\n   106→        \"validation\": VALIDATION_CONFIG,\n   107→        \"rate_limit\": RATE_LIMIT_CONFIG,\n   108→        \"logging\": LOGGING_CONFIG,\n   109→        \"paths\": {\n   110→            \"base_dir\": str(BASE_DIR),\n   111→            \"app_dir\": str(APP_DIR),\n   112→            \"test_data_dir\": str(TEST_DATA_DIR),\n   113→        }\n   114→    }\n   115→\n   116→def get_test_pdf_path() -> Path:\n   117→    \"\"\"Get the default test PDF path.\"\"\"\n   118→    return TEST_DATA_DIR / TEST_CONFIG[\"default_test_pdf\"]\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01P4wowDjNRdPPSSjkH6nhmg",
        "type": "tool_result",
        "content": "     1→\"\"\"\n     2→Logging configuration for the IRB KI Summary application.\n     3→Provides consistent logging across all modules.\n     4→\"\"\"\n     5→\n     6→import logging\n     7→import logging.handlers\n     8→import sys\n     9→from pathlib import Path\n    10→from typing import Optional\n    11→\n    12→# Import logging config\n    13→from config import LOGGING_CONFIG\n    14→\n    15→def setup_logger(\n    16→    name: str = \"irb_ki_summary\",\n    17→    level: Optional[str] = None,\n    18→    log_file: Optional[str] = None\n    19→) -> logging.Logger:\n    20→    \"\"\"\n    21→    Set up a logger with consistent formatting and handlers.\n    22→    \n    23→    Args:\n    24→        name: Logger name (typically module name)\n    25→        level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n    26→        log_file: Optional log file path\n    27→    \n    28→    Returns:\n    29→        Configured logger instance\n    30→    \"\"\"\n    31→    logger = logging.getLogger(name)\n    32→    \n    33→    # Use config or provided level\n    34→    log_level = level or LOGGING_CONFIG[\"level\"]\n    35→    logger.setLevel(getattr(logging, log_level))\n    36→    \n    37→    # Prevent duplicate handlers\n    38→    if logger.handlers:\n    39→        return logger\n    40→    \n    41→    # Create formatter\n    42→    formatter = logging.Formatter(LOGGING_CONFIG[\"format\"])\n    43→    \n    44→    # Console handler\n    45→    console_handler = logging.StreamHandler(sys.stdout)\n    46→    console_handler.setFormatter(formatter)\n    47→    logger.addHandler(console_handler)\n    48→    \n    49→    # File handler (if specified)\n    50→    file_path = log_file or LOGGING_CONFIG.get(\"file\")\n    51→    if file_path:\n    52→        try:\n    53→            # Ensure log directory exists\n    54→            log_path = Path(file_path)\n    55→            log_path.parent.mkdir(parents=True, exist_ok=True)\n    56→            \n    57→            # Rotating file handler\n    58→            file_handler = logging.handlers.RotatingFileHandler(\n    59→                file_path,\n    60→                maxBytes=LOGGING_CONFIG[\"max_bytes\"],\n    61→                backupCount=LOGGING_CONFIG[\"backup_count\"]\n    62→            )\n    63→            file_handler.setFormatter(formatter)\n    64→            logger.addHandler(file_handler)\n    65→        except Exception as e:\n    66→            logger.warning(f\"Could not set up file logging: {e}\")\n    67→    \n    68→    return logger\n    69→\n    70→# Create default application logger\n    71→app_logger = setup_logger(\"irb_ki_summary\")\n    72→\n    73→# Convenience functions for module-specific loggers\n    74→def get_logger(module_name: str) -> logging.Logger:\n    75→    \"\"\"Get a logger for a specific module.\"\"\"\n    76→    return setup_logger(f\"irb_ki_summary.{module_name}\")\n    77→\n    78→# Export commonly used log levels for convenience\n    79→DEBUG = logging.DEBUG\n    80→INFO = logging.INFO\n    81→WARNING = logging.WARNING\n    82→ERROR = logging.ERROR\n    83→CRITICAL = logging.CRITICAL\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "text",
        "text": "Now let me examine the core framework files:"
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01EKmwkURMLMeXgPSDwPcdq4",
        "name": "Read",
        "input": {
          "file_path": "/mnt/d/Common_Resources/irb-ki-summary/app/core/document_framework.py"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01RiaiLAENkvVBente4TkYm5",
        "name": "Read",
        "input": {
          "file_path": "/mnt/d/Common_Resources/irb-ki-summary/app/core/types.py"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01V882tMDMeZZQgqKb2s3MsL",
        "name": "Read",
        "input": {
          "file_path": "/mnt/d/Common_Resources/irb-ki-summary/app/core/plugin_manager.py"
        }
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01RiaiLAENkvVBente4TkYm5",
        "type": "tool_result",
        "content": "     1→\"\"\"\n     2→Type definitions for the Document Generation Framework.\n     3→\n     4→This module provides clear type definitions to improve code readability\n     5→and help junior developers understand data structures used throughout\n     6→the application.\n     7→\"\"\"\n     8→\n     9→from typing import TypedDict, List, Dict, Any, Optional, Literal\n    10→from dataclasses import dataclass\n    11→from enum import Enum\n    12→\n    13→\n    14→# Validation-related types\n    15→class ValidationResult(TypedDict):\n    16→    \"\"\"Structure for validation results returned by validators.\"\"\"\n    17→    passed: bool\n    18→    issues: List[str]\n    19→    warnings: List[str]\n    20→    info: List[str]\n    21→    consistency_metrics: Dict[str, float]\n    22→    content_analysis: Dict[str, Any]\n    23→\n    24→\n    25→class ConsistencyThresholds(TypedDict):\n    26→    \"\"\"Thresholds for consistency validation.\"\"\"\n    27→    coefficient_of_variation: float  # Target: < 15%\n    28→    structural_score: float  # Target: > 0.8\n    29→    min_sentences: int  # Minimum sentences required\n    30→    max_cv_tolerance: float  # Maximum CV tolerance\n    31→\n    32→\n    33→# Extraction-related types\n    34→class ExtractionField(TypedDict):\n    35→    \"\"\"Definition of a field to extract from documents.\"\"\"\n    36→    type: Literal[\"boolean\", \"enum\", \"text\", \"numeric\"]\n    37→    description: str\n    38→    options: Optional[List[str]]  # For enum types\n    39→    max_words: Optional[int]  # For text types\n    40→    required: bool\n    41→    default_value: Optional[Any]\n    42→\n    43→\n    44→class ExtractionResult(TypedDict):\n    45→    \"\"\"Result from document extraction process.\"\"\"\n    46→    field_name: str\n    47→    value: Any\n    48→    confidence: float\n    49→    source_page: Optional[int]\n    50→    source_text: Optional[str]\n    51→\n    52→\n    53→# Document processing types\n    54→class DocumentMetadata(TypedDict):\n    55→    \"\"\"Metadata associated with a processed document.\"\"\"\n    56→    filename: str\n    57→    page_count: int\n    58→    processing_time: float\n    59→    document_type: str\n    60→    template_used: Optional[str]\n    61→\n    62→\n    63→class SectionContent(TypedDict):\n    64→    \"\"\"Content for a single section of generated document.\"\"\"\n    65→    section_number: int\n    66→    section_title: str\n    67→    content: str\n    68→    word_count: int\n    69→    extracted_values: Dict[str, Any]\n    70→\n    71→\n    72→# Plugin-related types\n    73→class PluginInfo(TypedDict):\n    74→    \"\"\"Information about a loaded plugin.\"\"\"\n    75→    name: str\n    76→    version: str\n    77→    supported_document_types: List[str]\n    78→    description: str\n    79→    author: Optional[str]\n    80→    template_count: int\n    81→\n    82→\n    83→# Agent communication types\n    84→class AgentTaskRequest(TypedDict):\n    85→    \"\"\"Request sent to an agent for processing.\"\"\"\n    86→    task_type: str\n    87→    document_text: str\n    88→    parameters: Dict[str, Any]\n    89→    priority: Literal[\"low\", \"medium\", \"high\"]\n    90→    timeout_seconds: Optional[int]\n    91→\n    92→\n    93→class AgentTaskResponse(TypedDict):\n    94→    \"\"\"Response from an agent after processing.\"\"\"\n    95→    success: bool\n    96→    result: Any\n    97→    error_message: Optional[str]\n    98→    processing_time: float\n    99→    agent_name: str\n   100→\n   101→\n   102→# Template-related types\n   103→class TemplateSlotDefinition(TypedDict):\n   104→    \"\"\"Definition of a template slot for content generation.\"\"\"\n   105→    name: str\n   106→    slot_type: Literal[\"static\", \"extracted\", \"generated\", \"conditional\", \"propagated\"]\n   107→    extraction_query: str\n   108→    validation_rules: Dict[str, Any]\n   109→    default_value: Optional[str]\n   110→    max_length: Optional[int]\n   111→    is_critical: bool  # If true, value must be preserved exactly\n   112→\n   113→\n   114→class TemplateContext(TypedDict):\n   115→    \"\"\"Context provided to template engine for rendering.\"\"\"\n   116→    document_type: str\n   117→    extracted_values: Dict[str, Any]\n   118→    generated_content: Dict[str, str]\n   119→    metadata: DocumentMetadata\n   120→    user_parameters: Dict[str, Any]\n   121→\n   122→\n   123→# Configuration constants (extracted from magic numbers/strings)\n   124→class ValidationConstants:\n   125→    \"\"\"Constants used for validation throughout the framework.\"\"\"\n   126→    \n   127→    # Consistency thresholds\n   128→    TARGET_CV_PERCENTAGE = 15.0  # Target coefficient of variation\n   129→    MIN_STRUCTURAL_SCORE = 0.8  # Minimum structural consistency score\n   130→    \n   131→    # Content limits\n   132→    DEFAULT_MAX_WORDS = 30\n   133→    MIN_SENTENCE_COUNT = 3\n   134→    MAX_SENTENCE_COUNT = 100\n   135→    \n   136→    # Validation messages\n   137→    MISSING_REQUIRED_FIELD = \"Required field '{}' is missing\"\n   138→    EXCEEDS_LENGTH_LIMIT = \"Field '{}' exceeds maximum length of {} characters\"\n   139→    INVALID_ENUM_VALUE = \"Field '{}' has invalid value. Must be one of: {}\"\n   140→    \n   141→    # Prohibited phrases that indicate AI-generated artifacts\n   142→    PROHIBITED_PHRASES = [\n   143→        \"As an AI\", \"I cannot\", \"I don't have access\",\n   144→        \"Based on the document\", \"According to the text\",\n   145→        \"The document states\", \"It appears that\",\n   146→        \"<<\", \">>\", \"[[\", \"]]\",  # Template artifacts\n   147→        \"PLACEHOLDER\", \"TODO\", \"TBD\",\n   148→        \"In summary,\", \"To summarize,\", \"In conclusion,\"\n   149→    ]\n   150→\n   151→\n   152→class ProcessingConstants:\n   153→    \"\"\"Constants for document processing.\"\"\"\n   154→    \n   155→    # Chunk sizes for RAG pipeline\n   156→    DEFAULT_CHUNK_SIZE = 1024\n   157→    DEFAULT_CHUNK_OVERLAP = 128\n   158→    \n   159→    # Timeouts\n   160→    AGENT_TIMEOUT_SECONDS = 30\n   161→    EXTRACTION_TIMEOUT_SECONDS = 60\n   162→    GENERATION_TIMEOUT_SECONDS = 120\n   163→    \n   164→    # Retry configuration\n   165→    MAX_RETRIES = 3\n   166→    RETRY_DELAY_SECONDS = 2\n   167→    \n   168→    # Concurrency limits\n   169→    MAX_CONCURRENT_EXTRACTIONS = 5\n   170→    MAX_CONCURRENT_GENERATIONS = 3\n   171→\n   172→\n   173→@dataclass\n   174→class ProcessingError(Exception):\n   175→    \"\"\"Custom exception for document processing errors.\"\"\"\n   176→    error_code: str\n   177→    message: str\n   178→    details: Optional[Dict[str, Any]] = None\n   179→    \n   180→    def __str__(self):\n   181→        return f\"[{self.error_code}] {self.message}\"\n   182→\n   183→\n   184→# Error codes for better error handling\n   185→class ErrorCodes:\n   186→    \"\"\"Standardized error codes for the framework.\"\"\"\n   187→    \n   188→    # Document errors\n   189→    DOC_INVALID_FORMAT = \"DOC001\"\n   190→    DOC_PARSE_FAILED = \"DOC002\"\n   191→    DOC_TOO_LARGE = \"DOC003\"\n   192→    \n   193→    # Extraction errors\n   194→    EXT_FIELD_NOT_FOUND = \"EXT001\"\n   195→    EXT_TIMEOUT = \"EXT002\"\n   196→    EXT_LLM_ERROR = \"EXT003\"\n   197→    \n   198→    # Generation errors\n   199→    GEN_TEMPLATE_ERROR = \"GEN001\"\n   200→    GEN_VALIDATION_FAILED = \"GEN002\"\n   201→    GEN_TIMEOUT = \"GEN003\"\n   202→    \n   203→    # Plugin errors\n   204→    PLG_NOT_FOUND = \"PLG001\"\n   205→    PLG_LOAD_FAILED = \"PLG002\"\n   206→    PLG_INVALID_CONFIG = \"PLG003\"\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01V882tMDMeZZQgqKb2s3MsL",
        "type": "tool_result",
        "content": "     1→\"\"\"\n     2→Plugin Manager for Document Generation Framework\n     3→Implements runtime discovery and management of document type plugins\n     4→\"\"\"\n     5→from abc import ABC, abstractmethod\n     6→from dataclasses import dataclass\n     7→from typing import Dict, List, Optional, Any, Type\n     8→from pathlib import Path\n     9→import importlib.util\n    10→import inspect\n    11→from enum import Enum\n    12→\n    13→\n    14→class SlotType(Enum):\n    15→    \"\"\"Extended slot types for template system\"\"\"\n    16→    STATIC = \"static\"  # Fixed text\n    17→    EXTRACTED = \"extracted\"  # Retrieved from document\n    18→    GENERATED = \"generated\"  # LLM-generated content\n    19→    CONDITIONAL = \"conditional\"  # Context-dependent\n    20→    PROPAGATED = \"propagated\"  # Cross-template value propagation\n    21→\n    22→\n    23→@dataclass\n    24→class TemplateSlot:\n    25→    \"\"\"Enhanced template slot with propagation support\"\"\"\n    26→    name: str\n    27→    slot_type: SlotType\n    28→    extraction_query: str\n    29→    validation_rules: Dict[str, Any]\n    30→    default_value: Optional[str] = None\n    31→    max_length: Optional[int] = None\n    32→    cross_reference_slots: List[str] = None  # For value propagation\n    33→    intent_preservation: bool = False  # Critical values that must not change\n    34→    fallback_strategy: Optional[str] = None\n    35→    \n    36→    def __post_init__(self):\n    37→        if self.cross_reference_slots is None:\n    38→            self.cross_reference_slots = []\n    39→\n    40→\n    41→@dataclass\n    42→class ValidationRuleSet:\n    43→    \"\"\"Validation rules for document generation\"\"\"\n    44→    required_fields: List[str]\n    45→    max_lengths: Dict[str, int]\n    46→    allowed_values: Dict[str, List[str]]\n    47→    custom_validators: List[str]  # Function names to call\n    48→    intent_critical_fields: List[str]  # Fields that must preserve original intent\n    49→\n    50→\n    51→@dataclass\n    52→class TemplateCatalog:\n    53→    \"\"\"Catalog of available templates for a document type\"\"\"\n    54→    templates: Dict[str, str]  # template_id -> template_path\n    55→    default_template: str\n    56→    metadata: Dict[str, Any]\n    57→    \n    58→    def get_template(self, template_id: str = None) -> str:\n    59→        \"\"\"Get template path by ID or return default\"\"\"\n    60→        if template_id and template_id in self.templates:\n    61→            return self.templates[template_id]\n    62→        return self.templates.get(self.default_template, \"\")\n    63→\n    64→\n    65→class DocumentPlugin(ABC):\n    66→    \"\"\"Abstract base class for document generation plugins\"\"\"\n    67→    \n    68→    @abstractmethod\n    69→    def get_plugin_info(self) -> Dict[str, Any]:\n    70→        \"\"\"Return plugin metadata\"\"\"\n    71→        pass\n    72→    \n    73→    @abstractmethod\n    74→    def get_template_catalog(self) -> TemplateCatalog:\n    75→        \"\"\"Return available templates for this plugin\"\"\"\n    76→        pass\n    77→    \n    78→    @abstractmethod\n    79→    def get_specialized_agents(self) -> List[Any]:\n    80→        \"\"\"Return list of specialized agents for this document type\"\"\"\n    81→        pass\n    82→    \n    83→    @abstractmethod\n    84→    def get_validation_rules(self) -> ValidationRuleSet:\n    85→        \"\"\"Return validation rules for this document type\"\"\"\n    86→        pass\n    87→    \n    88→    @abstractmethod\n    89→    def supports_document_type(self, doc_type: str) -> bool:\n    90→        \"\"\"Check if this plugin supports the given document type\"\"\"\n    91→        pass\n    92→    \n    93→    @abstractmethod\n    94→    def get_sub_template_rules(self) -> Dict[str, Any]:\n    95→        \"\"\"Return rules for sub-template selection\"\"\"\n    96→        pass\n    97→    \n    98→    @abstractmethod\n    99→    def get_critical_values(self) -> List[str]:\n   100→        \"\"\"Return list of critical values that must be preserved\"\"\"\n   101→        pass\n   102→    \n   103→    @abstractmethod\n   104→    def resolve_template(self, parameters: Dict[str, Any]) -> str:\n   105→        \"\"\"Resolve which template to use based on parameters\"\"\"\n   106→        pass\n   107→\n   108→\n   109→class PluginManager:\n   110→    \"\"\"\n   111→    Manages document generation plugins with runtime discovery\n   112→    \"\"\"\n   113→    \n   114→    def __init__(self, plugin_dir: str = \"app/plugins\"):\n   115→        self.plugin_dir = Path(plugin_dir)\n   116→        self.plugins: Dict[str, DocumentPlugin] = {}\n   117→        self.plugin_registry: Dict[str, Type[DocumentPlugin]] = {}\n   118→        self._discover_plugins()\n   119→    \n   120→    def _discover_plugins(self):\n   121→        \"\"\"Discover and load plugins from plugin directory\"\"\"\n   122→        if not self.plugin_dir.exists():\n   123→            self.plugin_dir.mkdir(parents=True, exist_ok=True)\n   124→            return\n   125→        \n   126→        # Look for Python files in plugin directory\n   127→        for plugin_file in self.plugin_dir.glob(\"*.py\"):\n   128→            if plugin_file.name.startswith(\"_\"):\n   129→                continue  # Skip private modules\n   130→            \n   131→            try:\n   132→                # Load the module\n   133→                spec = importlib.util.spec_from_file_location(\n   134→                    plugin_file.stem, plugin_file\n   135→                )\n   136→                if spec and spec.loader:\n   137→                    module = importlib.util.module_from_spec(spec)\n   138→                    spec.loader.exec_module(module)\n   139→                    \n   140→                    # Find DocumentPlugin subclasses\n   141→                    for name, obj in inspect.getmembers(module):\n   142→                        if (inspect.isclass(obj) and \n   143→                            issubclass(obj, DocumentPlugin) and \n   144→                            obj != DocumentPlugin):\n   145→                            \n   146→                            # Register the plugin class\n   147→                            plugin_instance = obj()\n   148→                            plugin_info = plugin_instance.get_plugin_info()\n   149→                            plugin_id = plugin_info.get(\"id\", name.lower())\n   150→                            \n   151→                            self.plugin_registry[plugin_id] = obj\n   152→                            self.plugins[plugin_id] = plugin_instance\n   153→                            \n   154→                            print(f\"Discovered plugin: {plugin_id} from {plugin_file.name}\")\n   155→            \n   156→            except Exception as e:\n   157→                print(f\"Error loading plugin from {plugin_file}: {e}\")\n   158→    \n   159→    def get_plugin(self, document_type: str) -> Optional[DocumentPlugin]:\n   160→        \"\"\"\n   161→        Get plugin that supports the given document type\n   162→        \"\"\"\n   163→        # First check if document_type is a plugin ID\n   164→        if document_type in self.plugins:\n   165→            return self.plugins[document_type]\n   166→        \n   167→        # Otherwise find a plugin that supports this document type\n   168→        for plugin_id, plugin in self.plugins.items():\n   169→            if plugin.supports_document_type(document_type):\n   170→                return plugin\n   171→        \n   172→        return None\n   173→    \n   174→    def list_plugins(self) -> List[Dict[str, Any]]:\n   175→        \"\"\"List all available plugins and their info\"\"\"\n   176→        plugin_list = []\n   177→        for plugin_id, plugin in self.plugins.items():\n   178→            info = plugin.get_plugin_info()\n   179→            info[\"id\"] = plugin_id\n   180→            plugin_list.append(info)\n   181→        return plugin_list\n   182→    \n   183→    def register_plugin(self, plugin_id: str, plugin_class: Type[DocumentPlugin]):\n   184→        \"\"\"Manually register a plugin\"\"\"\n   185→        plugin_instance = plugin_class()\n   186→        self.plugin_registry[plugin_id] = plugin_class\n   187→        self.plugins[plugin_id] = plugin_instance\n   188→    \n   189→    def reload_plugins(self):\n   190→        \"\"\"Reload all plugins (useful for development)\"\"\"\n   191→        self.plugins.clear()\n   192→        self.plugin_registry.clear()\n   193→        self._discover_plugins()\n   194→    \n   195→    def get_supported_document_types(self) -> List[str]:\n   196→        \"\"\"Get list of all supported document types across all plugins\"\"\"\n   197→        supported_types = set()\n   198→        for plugin in self.plugins.values():\n   199→            plugin_info = plugin.get_plugin_info()\n   200→            if \"supported_types\" in plugin_info:\n   201→                supported_types.update(plugin_info[\"supported_types\"])\n   202→        return sorted(list(supported_types))\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  }
]