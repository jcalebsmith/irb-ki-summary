[
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01WX4hZuT8ag6AXGDzWLY5A2",
        "type": "tool_result",
        "content": "     1â†’#!/usr/bin/env npx tsx\n     2â†’import { \n     3â†’  executeStreamingResearch,\n     4â†’  ResearchEventType,\n     5â†’  ResearchEvent\n     6â†’} from '../networks/streamingResearchNetwork';\n     7â†’import * as dotenv from 'dotenv';\n     8â†’import * as path from 'path';\n     9â†’import * as fs from 'fs/promises';\n    10â†’import { neo4jStorage } from '../storage/neo4jStorage';\n    11â†’\n    12â†’// Load environment variables\n    13â†’dotenv.config({ path: path.resolve(process.cwd(), '.env') });\n    14â†’\n    15â†’// Configuration\n    16â†’const CONFIG = {\n    17â†’  // Default research query if none provided\n    18â†’  defaultQuery: 'What are the latest breakthroughs in quantum computing for 2024, and how do they impact practical applications?',\n    19â†’  \n    20â†’  // Research parameters\n    21â†’  maxIterations: 3,\n    22â†’  qualityThreshold: 75,\n    23â†’  parallelAgents: 3,\n    24â†’  progressiveReports: true,\n    25â†’  \n    26â†’  // Output configuration\n    27â†’  outputDir: path.join(process.cwd(), 'research-baselines'),\n    28â†’  saveBaseline: true,\n    29â†’  showRealTimeEvents: true,\n    30â†’  showProgressBar: true,\n    31â†’  \n    32â†’  // Timeout configuration (minutes)\n    33â†’  timeoutMinutes: 15\n    34â†’};\n    35â†’\n    36â†’// ANSI color codes for terminal output\n    37â†’const colors = {\n    38â†’  reset: '\\x1b[0m',\n    39â†’  bright: '\\x1b[1m',\n    40â†’  dim: '\\x1b[2m',\n    41â†’  red: '\\x1b[31m',\n    42â†’  green: '\\x1b[32m',\n    43â†’  yellow: '\\x1b[33m',\n    44â†’  blue: '\\x1b[34m',\n    45â†’  magenta: '\\x1b[35m',\n    46â†’  cyan: '\\x1b[36m',\n    47â†’  white: '\\x1b[37m'\n    48â†’};\n    49â†’\n    50â†’// Progress tracking\n    51â†’interface ResearchMetrics {\n    52â†’  startTime: number;\n    53â†’  endTime?: number;\n    54â†’  totalDuration?: number;\n    55â†’  events: ResearchEvent[];\n    56â†’  insights: any[];\n    57â†’  graphMetrics?: {\n    58â†’    nodes: number;\n    59â†’    relationships: number;\n    60â†’    coherence: number;\n    61â†’  };\n    62â†’  qualityScores: number[];\n    63â†’  finalReport?: string;\n    64â†’  iterations: number;\n    65â†’  agentsActivated: Set<string>;\n    66â†’  errorCount: number;\n    67â†’}\n    68â†’\n    69â†’// Format time elapsed\n    70â†’function formatTime(ms: number): string {\n    71â†’  const seconds = Math.floor(ms / 1000);\n    72â†’  const minutes = Math.floor(seconds / 60);\n    73â†’  const remainingSeconds = seconds % 60;\n    74â†’  return minutes > 0 \n    75â†’    ? `${minutes}m ${remainingSeconds}s`\n    76â†’    : `${remainingSeconds}s`;\n    77â†’}\n    78â†’\n    79â†’// Create progress bar\n    80â†’function createProgressBar(current: number, total: number, width: number = 30): string {\n    81â†’  const percentage = Math.min(100, Math.round((current / total) * 100));\n    82â†’  const filled = Math.round((percentage / 100) * width);\n    83â†’  const empty = width - filled;\n    84â†’  \n    85â†’  const bar = 'â–ˆ'.repeat(filled) + 'â–‘'.repeat(empty);\n    86â†’  return `[${bar}] ${percentage}%`;\n    87â†’}\n    88â†’\n    89â†’// Log with timestamp and color\n    90â†’function log(message: string, color: string = colors.white, prefix: string = '') {\n    91â†’  const timestamp = new Date().toISOString().split('T')[1].split('.')[0];\n    92â†’  console.log(`${colors.dim}[${timestamp}]${colors.reset} ${prefix}${color}${message}${colors.reset}`);\n    93â†’}\n    94â†’\n    95â†’// Main research execution\n    96â†’async function runResearchQuery(query: string): Promise<ResearchMetrics> {\n    97â†’  const metrics: ResearchMetrics = {\n    98â†’    startTime: Date.now(),\n    99â†’    events: [],\n   100â†’    insights: [],\n   101â†’    qualityScores: [],\n   102â†’    iterations: 0,\n   103â†’    agentsActivated: new Set(),\n   104â†’    errorCount: 0\n   105â†’  };\n   106â†’\n   107â†’  log(`Starting Deep Research Pipeline`, colors.bright + colors.cyan, 'ğŸš€ ');\n   108â†’  log(`Query: \"${query}\"`, colors.white);\n   109â†’  log(`Configuration:`, colors.dim);\n   110â†’  log(`  Max Iterations: ${CONFIG.maxIterations}`, colors.dim);\n   111â†’  log(`  Quality Threshold: ${CONFIG.qualityThreshold}`, colors.dim);\n   112â†’  log(`  Parallel Agents: ${CONFIG.parallelAgents}`, colors.dim);\n   113â†’  console.log('');\n   114â†’\n   115â†’  // Create abort controller for timeout\n   116â†’  const abortController = new AbortController();\n   117â†’  const timeout = setTimeout(() => {\n   118â†’    log(`Research timeout reached (${CONFIG.timeoutMinutes} minutes)`, colors.yellow, 'â±ï¸ ');\n   119â†’    abortController.abort();\n   120â†’  }, CONFIG.timeoutMinutes * 60 * 1000);\n   121â†’\n   122â†’  try {\n   123â†’    // Execute streaming research\n   124â†’    for await (const event of executeStreamingResearch(query, {\n   125â†’      maxIterations: CONFIG.maxIterations,\n   126â†’      qualityThreshold: CONFIG.qualityThreshold,\n   127â†’      parallelAgents: CONFIG.parallelAgents,\n   128â†’      progressiveReports: CONFIG.progressiveReports,\n   129â†’      abortSignal: abortController.signal\n   130â†’    })) {\n   131â†’      metrics.events.push(event);\n   132â†’      const elapsed = Date.now() - metrics.startTime;\n   133â†’      const elapsedStr = formatTime(elapsed);\n   134â†’\n   135â†’      // Handle different event types\n   136â†’      switch (event.type) {\n   137â†’        case ResearchEventType.RESEARCH_STARTED:\n   138â†’          log(`Research initialized`, colors.green, 'âœ… ');\n   139â†’          break;\n   140â†’\n   141â†’        case ResearchEventType.AGENT_ACTIVATED:\n   142â†’          if (event.agentName) {\n   143â†’            metrics.agentsActivated.add(event.agentName);\n   144â†’            if (CONFIG.showRealTimeEvents) {\n   145â†’              log(`Agent: ${event.agentName}`, colors.blue, 'ğŸ¤– ');\n   146â†’            }\n   147â†’          }\n   148â†’          break;\n   149â†’\n   150â†’        case ResearchEventType.INSIGHT_DISCOVERED:\n   151â†’          metrics.insights.push(event.data);\n   152â†’          if (CONFIG.showRealTimeEvents) {\n   153â†’            const insightPreview = event.data?.insight \n   154â†’              ? event.data.insight.substring(0, 80) + (event.data.insight.length > 80 ? '...' : '')\n   155â†’              : 'New insight';\n   156â†’            log(`Insight: ${insightPreview}`, colors.magenta, 'ğŸ’¡ ');\n   157â†’          }\n   158â†’          \n   159â†’          // Show progress bar\n   160â†’          if (CONFIG.showProgressBar && metrics.iterations > 0) {\n   161â†’            const progress = metrics.insights.length;\n   162â†’            const estimatedTotal = metrics.iterations * 10; // Estimate based on iteration\n   163â†’            const progressBar = createProgressBar(progress, estimatedTotal);\n   164â†’            process.stdout.write(`\\r${colors.cyan}Progress: ${progressBar} | ${metrics.insights.length} insights | ${elapsedStr}${colors.reset}`);\n   165â†’          }\n   166â†’          break;\n   167â†’\n   168â†’        case ResearchEventType.GRAPH_UPDATED:\n   169â†’          if (event.data) {\n   170â†’            metrics.graphMetrics = {\n   171â†’              nodes: event.data.nodes || 0,\n   172â†’              relationships: event.data.relationships || 0,\n   173â†’              coherence: event.data.coherence || 0\n   174â†’            };\n   175â†’            if (CONFIG.showRealTimeEvents) {\n   176â†’              log(`Graph: ${metrics.graphMetrics.nodes} nodes, ${metrics.graphMetrics.relationships} edges`, colors.cyan, 'ğŸ”— ');\n   177â†’            }\n   178â†’          }\n   179â†’          break;\n   180â†’\n   181â†’        case ResearchEventType.QUALITY_ASSESSED:\n   182â†’          const qualityScore = event.data?.scores?.overallQuality || 0;\n   183â†’          metrics.qualityScores.push(qualityScore);\n   184â†’          log(`Quality Score: ${qualityScore}/${CONFIG.qualityThreshold}`, \n   185â†’            qualityScore >= CONFIG.qualityThreshold ? colors.green : colors.yellow, \n   186â†’            'ğŸ“Š ');\n   187â†’          break;\n   188â†’\n   189â†’        case ResearchEventType.ITERATION_COMPLETE:\n   190â†’          metrics.iterations++;\n   191â†’          console.log(''); // Clear progress bar line\n   192â†’          log(`Iteration ${metrics.iterations} complete`, colors.white, 'ğŸ”„ ');\n   193â†’          break;\n   194â†’\n   195â†’        case ResearchEventType.RESEARCH_COMPLETE:\n   196â†’          clearTimeout(timeout);\n   197â†’          console.log(''); // Clear progress bar line\n   198â†’          log(`Research Complete!`, colors.bright + colors.green, 'ğŸ ');\n   199â†’          \n   200â†’          // Extract final report if available\n   201â†’          if (event.data?.report) {\n   202â†’            metrics.finalReport = event.data.report;\n   203â†’          }\n   204â†’          break;\n   205â†’\n   206â†’        case ResearchEventType.ERROR_OCCURRED:\n   207â†’          metrics.errorCount++;\n   208â†’          log(`Error: ${event.data?.error || 'Unknown error'}`, colors.red, 'âŒ ');\n   209â†’          break;\n   210â†’      }\n   211â†’    }\n   212â†’\n   213â†’  } catch (error: any) {\n   214â†’    if (error.name === 'AbortError') {\n   215â†’      log(`Research aborted (timeout or user cancellation)`, colors.yellow, 'âš ï¸ ');\n   216â†’    } else {\n   217â†’      log(`Research failed: ${error.message}`, colors.red, 'âŒ ');\n   218â†’      throw error;\n   219â†’    }\n   220â†’  } finally {\n   221â†’    clearTimeout(timeout);\n   222â†’    metrics.endTime = Date.now();\n   223â†’    metrics.totalDuration = metrics.endTime - metrics.startTime;\n   224â†’  }\n   225â†’\n   226â†’  return metrics;\n   227â†’}\n   228â†’\n   229â†’// Save baseline results\n   230â†’async function saveBaseline(query: string, metrics: ResearchMetrics): Promise<string> {\n   231â†’  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n   232â†’  const filename = `baseline-${timestamp}.json`;\n   233â†’  const filepath = path.join(CONFIG.outputDir, filename);\n   234â†’\n   235â†’  // Ensure output directory exists\n   236â†’  await fs.mkdir(CONFIG.outputDir, { recursive: true });\n   237â†’\n   238â†’  // Prepare baseline data\n   239â†’  const baseline = {\n   240â†’    timestamp: new Date().toISOString(),\n   241â†’    query,\n   242â†’    configuration: {\n   243â†’      maxIterations: CONFIG.maxIterations,\n   244â†’      qualityThreshold: CONFIG.qualityThreshold,\n   245â†’      parallelAgents: CONFIG.parallelAgents\n   246â†’    },\n   247â†’    metrics: {\n   248â†’      duration: metrics.totalDuration,\n   249â†’      iterations: metrics.iterations,\n   250â†’      totalEvents: metrics.events.length,\n   251â†’      totalInsights: metrics.insights.length,\n   252â†’      agentsActivated: Array.from(metrics.agentsActivated),\n   253â†’      errorCount: metrics.errorCount,\n   254â†’      averageQuality: metrics.qualityScores.length > 0 \n   255â†’        ? metrics.qualityScores.reduce((a, b) => a + b, 0) / metrics.qualityScores.length \n   256â†’        : 0,\n   257â†’      finalQuality: metrics.qualityScores[metrics.qualityScores.length - 1] || 0,\n   258â†’      graphMetrics: metrics.graphMetrics\n   259â†’    },\n   260â†’    insights: metrics.insights,\n   261â†’    report: metrics.finalReport,\n   262â†’    events: CONFIG.saveBaseline ? metrics.events : undefined\n   263â†’  };\n   264â†’\n   265â†’  // Save to file\n   266â†’  await fs.writeFile(filepath, JSON.stringify(baseline, null, 2));\n   267â†’  \n   268â†’  // Also save the report as markdown if available\n   269â†’  if (metrics.finalReport) {\n   270â†’    const reportPath = path.join(CONFIG.outputDir, `report-${timestamp}.md`);\n   271â†’    await fs.writeFile(reportPath, metrics.finalReport);\n   272â†’    return `${filepath} and ${reportPath}`;\n   273â†’  }\n   274â†’\n   275â†’  return filepath;\n   276â†’}\n   277â†’\n   278â†’// Display final report\n   279â†’function displayReport(metrics: ResearchMetrics) {\n   280â†’  console.log('\\n' + '='.repeat(80));\n   281â†’  console.log(colors.bright + colors.cyan + 'FINAL RESEARCH REPORT' + colors.reset);\n   282â†’  console.log('='.repeat(80) + '\\n');\n   283â†’\n   284â†’  // Display metrics summary\n   285â†’  console.log(colors.bright + 'Research Metrics:' + colors.reset);\n   286â†’  console.log(`  Duration: ${formatTime(metrics.totalDuration || 0)}`);\n   287â†’  console.log(`  Iterations: ${metrics.iterations}`);\n   288â†’  console.log(`  Total Insights: ${metrics.insights.length}`);\n   289â†’  console.log(`  Agents Used: ${metrics.agentsActivated.size} (${Array.from(metrics.agentsActivated).join(', ')})`);\n   290â†’  console.log(`  Final Quality: ${metrics.qualityScores[metrics.qualityScores.length - 1] || 'N/A'}/100`);\n   291â†’  \n   292â†’  if (metrics.graphMetrics) {\n   293â†’    console.log(`  Knowledge Graph: ${metrics.graphMetrics.nodes} entities, ${metrics.graphMetrics.relationships} relationships`);\n   294â†’    console.log(`  Graph Coherence: ${(metrics.graphMetrics.coherence * 100).toFixed(1)}%`);\n   295â†’  }\n   296â†’\n   297â†’  // Display the actual report content\n   298â†’  if (metrics.finalReport) {\n   299â†’    console.log('\\n' + colors.bright + 'Report Content:' + colors.reset);\n   300â†’    console.log('-'.repeat(80));\n   301â†’    console.log(metrics.finalReport);\n   302â†’    console.log('-'.repeat(80));\n   303â†’  } else {\n   304â†’    console.log('\\n' + colors.yellow + 'No final report generated' + colors.reset);\n   305â†’    \n   306â†’    // Show top insights instead\n   307â†’    if (metrics.insights.length > 0) {\n   308â†’      console.log('\\n' + colors.bright + 'Top Insights Discovered:' + colors.reset);\n   309â†’      metrics.insights.slice(0, 5).forEach((insight, i) => {\n   310â†’        console.log(`${i + 1}. ${insight.insight || insight}`);\n   311â†’        if (insight.confidence) {\n   312â†’          console.log(`   Confidence: ${(insight.confidence * 100).toFixed(0)}%`);\n   313â†’        }\n   314â†’      });\n   315â†’    }\n   316â†’  }\n   317â†’\n   318â†’  console.log('\\n' + '='.repeat(80) + '\\n');\n   319â†’}\n   320â†’\n   321â†’// Main execution\n   322â†’async function main() {\n   323â†’  // Check environment\n   324â†’  console.log(colors.dim + 'Environment Check:' + colors.reset);\n   325â†’  console.log(`  EXA_API_KEY: ${process.env.EXA_API_KEY ? 'âœ…' : 'âŒ'}`);\n   326â†’  console.log(`  OPENAI_API_KEY: ${process.env.OPENAI_API_KEY ? 'âœ…' : 'âŒ'}`);\n   327â†’  console.log(`  NEO4J_URI: ${process.env.NEO4J_URI ? 'âœ…' : 'âŒ'}`);\n   328â†’  console.log('');\n   329â†’\n   330â†’  // Get query from command line or use default\n   331â†’  const query = process.argv[2] || CONFIG.defaultQuery;\n   332â†’\n   333â†’  try {\n   334â†’    // Test Neo4j connection if configured\n   335â†’    if (process.env.NEO4J_URI) {\n   336â†’      log('Testing knowledge graph database connection...', colors.dim);\n   337â†’      const isConnected = await neo4jStorage.testConnection();\n   338â†’      if (!isConnected) {\n   339â†’        log('Warning: Neo4j connection failed, continuing without graph', colors.yellow);\n   340â†’      }\n   341â†’    }\n   342â†’\n   343â†’    // Run the research\n   344â†’    const metrics = await runResearchQuery(query);\n   345â†’\n   346â†’    // Display the report\n   347â†’    displayReport(metrics);\n   348â†’\n   349â†’    // Save baseline if configured\n   350â†’    if (CONFIG.saveBaseline) {\n   351â†’      const savedPath = await saveBaseline(query, metrics);\n   352â†’      log(`Baseline saved to: ${savedPath}`, colors.green, 'ğŸ’¾ ');\n   353â†’    }\n   354â†’\n   355â†’    // Cleanup\n   356â†’    if (process.env.NEO4J_URI) {\n   357â†’      await neo4jStorage.close();\n   358â†’    }\n   359â†’\n   360â†’    // Exit successfully\n   361â†’    process.exit(0);\n   362â†’\n   363â†’  } catch (error: any) {\n   364â†’    console.error(colors.red + 'Fatal error:' + colors.reset, error.message);\n   365â†’    \n   366â†’    // Cleanup on error\n   367â†’    try {\n   368â†’      await neo4jStorage.close();\n   369â†’    } catch {}\n   370â†’    \n   371â†’    process.exit(1);\n   372â†’  }\n   373â†’}\n   374â†’\n   375â†’// Handle interrupts gracefully\n   376â†’process.on('SIGINT', async () => {\n   377â†’  console.log('\\n' + colors.yellow + 'Research interrupted by user' + colors.reset);\n   378â†’  try {\n   379â†’    await neo4jStorage.close();\n   380â†’  } catch {}\n   381â†’  process.exit(0);\n   382â†’});\n   383â†’\n   384â†’// Run if executed directly\n   385â†’import { fileURLToPath } from 'url';\n   386â†’if (process.argv[1] === fileURLToPath(import.meta.url)) {\n   387â†’  main().catch(console.error);\n   388â†’}\n   389â†’\n   390â†’export { runResearchQuery, saveBaseline, CONFIG };\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01YGRxGoet9mt8pvTX4WUGNt",
        "type": "tool_result",
        "content": "     1â†’import { AgentNetwork } from '@mastra/core/network';\n     2â†’import { openai } from '@ai-sdk/openai';\n     3â†’import { z } from 'zod';\n     4â†’import { researchCoordinatorAgent } from '../agents/researchCoordinatorAgent';\n     5â†’import { qualityAssessmentAgent } from '../agents/qualityAssessmentAgent';\n     6â†’import { refinementAgent } from '../agents/refinementAgent';\n     7â†’import { researchAgent } from '../agents/researchAgent';\n     8â†’import { streamingResearchAgent, extractInsightsFromText } from '../agents/streamingResearchAgent';\n     9â†’import { reportAgent } from '../agents/reportAgent';\n    10â†’import { evaluationAgent } from '../agents/evaluationAgent';\n    11â†’import { learningExtractionAgent } from '../agents/learningExtractionAgent';\n    12â†’import { webSummarizationAgent } from '../agents/webSummarizationAgent';\n    13â†’import { knowledgeGraphAgent, buildKnowledgeGraph, KnowledgeGraph } from '../agents/knowledgeGraphAgent';\n    14â†’import { neo4jStorage } from '../storage/neo4jStorage';\n    15â†’import { StreamingKnowledgeGraphAgent } from '../agents/streamingKnowledgeGraphAgent';\n    16â†’\n    17â†’// Event types for streaming\n    18â†’export enum ResearchEventType {\n    19â†’  RESEARCH_STARTED = 'research_started',\n    20â†’  AGENT_ACTIVATED = 'agent_activated',\n    21â†’  INSIGHT_DISCOVERED = 'insight_discovered',\n    22â†’  GRAPH_UPDATED = 'graph_updated',\n    23â†’  QUALITY_ASSESSED = 'quality_assessed',\n    24â†’  ITERATION_COMPLETE = 'iteration_complete',\n    25â†’  RESEARCH_COMPLETE = 'research_complete',\n    26â†’  ERROR_OCCURRED = 'error_occurred',\n    27â†’  EVALUATION_PERFORMED = 'evaluation_performed',\n    28â†’  LEARNING_EXTRACTED = 'learning_extracted',\n    29â†’  WEB_SUMMARIZED = 'web_summarized'\n    30â†’}\n    31â†’\n    32â†’export interface ResearchEvent {\n    33â†’  type: ResearchEventType;\n    34â†’  timestamp: string;\n    35â†’  data: any;\n    36â†’  agentName?: string;\n    37â†’  confidence?: number;\n    38â†’}\n    39â†’\n    40â†’// Schema for streaming research state\n    41â†’const StreamingResearchState = z.object({\n    42â†’  query: z.string(),\n    43â†’  status: z.enum(['initializing', 'researching', 'refining', 'synthesizing', 'complete']),\n    44â†’  currentIteration: z.number(),\n    45â†’  qualityScore: z.number(),\n    46â†’  insights: z.array(z.object({\n    47â†’    insight: z.string(),\n    48â†’    confidence: z.number(),\n    49â†’    timestamp: z.string(),\n    50â†’    source: z.string()\n    51â†’  })),\n    52â†’  graph: z.object({\n    53â†’    nodes: z.number(),\n    54â†’    relationships: z.number(),\n    55â†’    coherence: z.number()\n    56â†’  }).optional(),\n    57â†’  errors: z.array(z.string())\n    58â†’});\n    59â†’\n    60â†’export const streamingResearchNetwork = new AgentNetwork({\n    61â†’  name: 'Streaming Research Network',\n    62â†’  agents: [\n    63â†’    researchCoordinatorAgent,\n    64â†’    researchAgent,\n    65â†’    qualityAssessmentAgent,\n    66â†’    refinementAgent,\n    67â†’    evaluationAgent,\n    68â†’    learningExtractionAgent,\n    69â†’    webSummarizationAgent,\n    70â†’    reportAgent,\n    71â†’    knowledgeGraphAgent,\n    72â†’  ],\n    73â†’  model: openai('gpt-4.1'),\n    74â†’  instructions: `\n    75â†’    You are a streaming research coordination system that provides real-time updates as research progresses.\n    76â†’    \n    77â†’    Your available agents are:\n    78â†’    1. Research Coordinator Agent: Creates research plans and determines quality criteria\n    79â†’    2. Research Agent: Conducts the actual research using web search and synthesis\n    80â†’    3. Quality Assessment Agent: Evaluates research completeness and quality\n    81â†’    4. Refinement Agent: Generates targeted queries to address gaps\n    82â†’    5. Evaluation Agent: Assesses relevance of search results\n    83â†’    6. Learning Extraction Agent: Extracts key learnings and generates follow-up questions\n    84â†’    7. Web Summarization Agent: Compresses web content while preserving critical information\n    85â†’    8. Report Agent: Generates comprehensive reports from research data\n    86â†’    9. Knowledge Graph Agent: Builds semantic knowledge graphs for deep understanding\n    87â†’    \n    88â†’    Key Capabilities:\n    89â†’    1. Stream research events as they occur\n    90â†’    2. Execute agents in parallel when possible\n    91â†’    3. Provide progressive insights and graph updates\n    92â†’    4. Enable early termination with partial results\n    93â†’    5. Support interactive refinement based on user feedback\n    94â†’    \n    95â†’    Parallel Execution Strategy:\n    96â†’    - Research multiple queries simultaneously\n    97â†’    - Build graph incrementally as data arrives\n    98â†’    - Assess quality continuously, not just at boundaries\n    99â†’    - Stream insights immediately upon discovery\n   100â†’    \n   101â†’    Always prioritize user experience through immediate feedback and progressive enhancement.\n   102â†’  `,\n   103â†’});\n   104â†’\n   105â†’// Main streaming execution function with semantic synthesis\n   106â†’export async function* executeStreamingResearch(\n   107â†’  query: string,\n   108â†’  options: {\n   109â†’    maxIterations?: number;\n   110â†’    qualityThreshold?: number;\n   111â†’    parallelAgents?: number;\n   112â†’    abortSignal?: AbortSignal;\n   113â†’    progressiveReports?: boolean;\n   114â†’  } = {}\n   115â†’): AsyncGenerator<ResearchEvent, void, unknown> {\n   116â†’  const maxIterations = options.maxIterations || 3;\n   117â†’  const qualityThreshold = options.qualityThreshold || 75;\n   118â†’  const parallelAgents = options.parallelAgents || 3;\n   119â†’  const progressiveReports = options.progressiveReports !== false;\n   120â†’  const abortSignal = options.abortSignal;\n   121â†’  \n   122â†’  // Initialize streaming knowledge graph for real-time processing\n   123â†’  const streamingGraph = new StreamingKnowledgeGraphAgent(query);\n   124â†’  let knowledgeGraph: KnowledgeGraph | null = null;\n   125â†’  let currentQualityScore = 0;\n   126â†’  let iterationCount = 0;\n   127â†’  let isAborted = false;\n   128â†’  \n   129â†’  // Non-blocking event queue for true streaming\n   130â†’  const eventQueue: ResearchEvent[] = [];\n   131â†’  let eventQueueResolver: ((value: void) => void) | null = null;\n   132â†’  \n   133â†’  // Check for abort signal\n   134â†’  if (abortSignal) {\n   135â†’    abortSignal.addEventListener('abort', () => {\n   136â†’      isAborted = true;\n   137â†’    });\n   138â†’  }\n   139â†’  \n   140â†’  try {\n   141â†’    // Emit start event\n   142â†’    yield {\n   143â†’      type: ResearchEventType.RESEARCH_STARTED,\n   144â†’      timestamp: new Date().toISOString(),\n   145â†’      data: { query, options: { maxIterations, qualityThreshold, parallelAgents } }\n   146â†’    };\n   147â†’    \n   148â†’    // Step 1: Create research plan (streamed)\n   149â†’    yield {\n   150â†’      type: ResearchEventType.AGENT_ACTIVATED,\n   151â†’      timestamp: new Date().toISOString(),\n   152â†’      agentName: 'Research Coordinator',\n   153â†’      data: { action: 'Creating research plan' }\n   154â†’    };\n   155â†’    \n   156â†’    const researchPlan = await researchCoordinatorAgent.generate(\n   157â†’      [{ role: 'user', content: `Create a research plan for: ${query}` }],\n   158â†’      { \n   159â†’        experimental_output: z.object({\n   160â†’          initialQueries: z.array(z.string()),\n   161â†’          qualityCriteria: z.array(z.string()),\n   162â†’          expectedDepth: z.string()\n   163â†’        })\n   164â†’      }\n   165â†’    );\n   166â†’    \n   167â†’    if (isAborted) {\n   168â†’      yield {\n   169â†’        type: ResearchEventType.ERROR_OCCURRED,\n   170â†’        timestamp: new Date().toISOString(),\n   171â†’        data: { error: 'Research aborted by user' }\n   172â†’      };\n   173â†’      return;\n   174â†’    }\n   175â†’    \n   176â†’    // Step 2: TRUE PARALLEL EXECUTION with semantic synthesis\n   177â†’    const researchTasks = researchPlan.object.initialQueries\n   178â†’      .slice(0, parallelAgents)\n   179â†’      .map((subQuery, index) => ({\n   180â†’        agentId: `Research Agent ${index + 1}`,\n   181â†’        query: subQuery,\n   182â†’        index\n   183â†’      }));\n   184â†’    \n   185â†’    // Track active agents and completion\n   186â†’    const activeAgents = new Set<string>();\n   187â†’    const completedAgents = new Set<string>();\n   188â†’    let totalInsightsProcessed = 0;\n   189â†’    let lastProgressReportTime = Date.now();\n   190â†’    \n   191â†’    // Launch agents truly in parallel without blocking\n   192â†’    for (const task of researchTasks) {\n   193â†’      activeAgents.add(task.agentId);\n   194â†’      \n   195â†’      // Emit activation event immediately\n   196â†’      yield {\n   197â†’        type: ResearchEventType.AGENT_ACTIVATED,\n   198â†’        timestamp: new Date().toISOString(),\n   199â†’        agentName: task.agentId,\n   200â†’        data: { query: task.query }\n   201â†’      };\n   202â†’      \n   203â†’      // Launch agent asynchronously - don't await!\n   204â†’      (async () => {\n   205â†’        try {\n   206â†’          // Step 1: Execute research with research agent\n   207â†’          const researchResult = await researchAgent.generate(\n   208â†’            [{\n   209â†’              role: 'user',\n   210â†’              content: `Research this specific aspect: \"${task.query}\"\n   211â†’              \n   212â†’              Use the two-phase process:\n   213â†’              Phase 1: Search for 2-3 initial queries about this topic\n   214â†’              Phase 2: Search for follow-up questions from the learnings (then STOP)\n   215â†’              \n   216â†’              Return findings as learnings with follow-up questions.`\n   217â†’            }],\n   218â†’            {\n   219â†’              maxSteps: 10,\n   220â†’            }\n   221â†’          );\n   222â†’          \n   223â†’          if (isAborted) return;\n   224â†’          \n   225â†’          // Step 2: Use webSummarizationAgent to compress content if needed\n   226â†’          let summarizedContent = researchResult.text;\n   227â†’          if (researchResult.text && researchResult.text.length > 5000) {\n   228â†’            eventQueue.push({\n   229â†’              type: ResearchEventType.AGENT_ACTIVATED,\n   230â†’              timestamp: new Date().toISOString(),\n   231â†’              agentName: 'Web Summarization Agent',\n   232â†’              data: { action: 'Compressing research content' }\n   233â†’            });\n   234â†’            \n   235â†’            const summarizationResult = await webSummarizationAgent.generate(\n   236â†’              [{\n   237â†’                role: 'user',\n   238â†’                content: `Summarize this research content while preserving all key insights and findings: ${researchResult.text}`\n   239â†’              }],\n   240â†’              {\n   241â†’                experimental_output: z.object({\n   242â†’                  summary: z.string(),\n   243â†’                  keyPoints: z.array(z.string()),\n   244â†’                  preservedInsights: z.number()\n   245â†’                })\n   246â†’              }\n   247â†’            );\n   248â†’            \n   249â†’            if (summarizationResult.object) {\n   250â†’              summarizedContent = summarizationResult.object.summary;\n   251â†’              eventQueue.push({\n   252â†’                type: ResearchEventType.WEB_SUMMARIZED,\n   253â†’                timestamp: new Date().toISOString(),\n   254â†’                agentName: task.agentId,\n   255â†’                data: {\n   256â†’                  originalLength: researchResult.text.length,\n   257â†’                  summarizedLength: summarizedContent.length,\n   258â†’                  keyPointsCount: summarizationResult.object.keyPoints.length\n   259â†’                }\n   260â†’              });\n   261â†’            }\n   262â†’          }\n   263â†’          \n   264â†’          // Step 3: Use learningExtractionAgent for structured extraction\n   265â†’          const learningResult = await learningExtractionAgent.generate(\n   266â†’            [{\n   267â†’              role: 'user',\n   268â†’              content: `Extract structured learnings from this research: ${summarizedContent}`\n   269â†’            }],\n   270â†’            {\n   271â†’              experimental_output: z.object({\n   272â†’                learnings: z.array(z.object({\n   273â†’                  learning: z.string(),\n   274â†’                  confidence: z.number(),\n   275â†’                  followUpQuestions: z.array(z.string()),\n   276â†’                  relevance: z.enum(['high', 'medium', 'low'])\n   277â†’                }))\n   278â†’              })\n   279â†’            }\n   280â†’          );\n   281â†’          \n   282â†’          if (isAborted) return;\n   283â†’          \n   284â†’          // Step 4: Use evaluationAgent to assess relevance\n   285â†’          if (learningResult.object && learningResult.object.learnings.length > 0) {\n   286â†’            const evaluationResult = await evaluationAgent.generate(\n   287â†’              [{\n   288â†’                role: 'user',\n   289â†’                content: `Evaluate the relevance of these learnings to the original query \"${query}\": ${JSON.stringify(learningResult.object.learnings)}`\n   290â†’              }],\n   291â†’              {\n   292â†’                experimental_output: z.object({\n   293â†’                  evaluatedLearnings: z.array(z.object({\n   294â†’                    learning: z.string(),\n   295â†’                    relevanceScore: z.number(),\n   296â†’                    keepForProcessing: z.boolean()\n   297â†’                  }))\n   298â†’                })\n   299â†’              }\n   300â†’            );\n   301â†’            \n   302â†’            eventQueue.push({\n   303â†’              type: ResearchEventType.EVALUATION_PERFORMED,\n   304â†’              timestamp: new Date().toISOString(),\n   305â†’              agentName: task.agentId,\n   306â†’              data: {\n   307â†’                totalLearnings: learningResult.object.learnings.length,\n   308â†’                relevantLearnings: evaluationResult.object?.evaluatedLearnings.filter(l => l.keepForProcessing).length || 0\n   309â†’              }\n   310â†’            });\n   311â†’            \n   312â†’            // Process only relevant learnings\n   313â†’            const relevantLearnings = evaluationResult.object?.evaluatedLearnings.filter(l => l.keepForProcessing) || [];\n   314â†’            \n   315â†’            for (const evaluatedLearning of relevantLearnings) {\n   316â†’              if (isAborted) break;\n   317â†’              \n   318â†’              totalInsightsProcessed++;\n   319â†’              console.log(`ğŸ“ [${task.agentId}] Processing learning ${totalInsightsProcessed}: \"${evaluatedLearning.learning.substring(0, 60)}...\"`);\n   320â†’              \n   321â†’              // Find original learning for follow-up questions\n   322â†’              const originalLearning = learningResult.object.learnings.find(l => \n   323â†’                l.learning === evaluatedLearning.learning\n   324â†’              );\n   325â†’              \n   326â†’              // Add to streaming knowledge graph for real-time processing\n   327â†’              await streamingGraph.addInsight({\n   328â†’                insight: evaluatedLearning.learning,\n   329â†’                source: task.query,\n   330â†’                confidence: evaluatedLearning.relevanceScore / 100,\n   331â†’                followUpQuestions: originalLearning?.followUpQuestions || []\n   332â†’              });\n   333â†’              \n   334â†’              // Get current graph state for event\n   335â†’              const graphState = await streamingGraph.getCurrentGraph();\n   336â†’              \n   337â†’              // Push learning event\n   338â†’              eventQueue.push({\n   339â†’                type: ResearchEventType.LEARNING_EXTRACTED,\n   340â†’                timestamp: new Date().toISOString(),\n   341â†’                agentName: task.agentId,\n   342â†’                data: {\n   343â†’                  learning: evaluatedLearning.learning,\n   344â†’                  source: task.query,\n   345â†’                  followUpQuestions: originalLearning?.followUpQuestions || [],\n   346â†’                  confidence: originalLearning?.confidence || 0.8,\n   347â†’                  relevanceScore: evaluatedLearning.relevanceScore,\n   348â†’                  insightNumber: totalInsightsProcessed,\n   349â†’                  graphMetrics: {\n   350â†’                    totalNodes: graphState.metadata.totalNodes,\n   351â†’                    totalRelationships: graphState.metadata.totalRelationships,\n   352â†’                    contradictions: graphState.contradictions.length,\n   353â†’                    gaps: graphState.gaps.length\n   354â†’                  }\n   355â†’                }\n   356â†’              });\n   357â†’              \n   358â†’              // Also emit as insight for backward compatibility\n   359â†’              eventQueue.push({\n   360â†’                type: ResearchEventType.INSIGHT_DISCOVERED,\n   361â†’                timestamp: new Date().toISOString(),\n   362â†’                agentName: task.agentId,\n   363â†’                data: {\n   364â†’                  insight: evaluatedLearning.learning,\n   365â†’                  source: task.query,\n   366â†’                  followUpQuestions: originalLearning?.followUpQuestions || [],\n   367â†’                  insightNumber: totalInsightsProcessed,\n   368â†’                  graphMetrics: {\n   369â†’                    totalNodes: graphState.metadata.totalNodes,\n   370â†’                    totalRelationships: graphState.metadata.totalRelationships,\n   371â†’                    contradictions: graphState.contradictions.length,\n   372â†’                    gaps: graphState.gaps.length\n   373â†’                  }\n   374â†’                },\n   375â†’                confidence: evaluatedLearning.relevanceScore / 100\n   376â†’              });\n   377â†’              \n   378â†’              // Notify that new events are available\n   379â†’              if (eventQueueResolver) {\n   380â†’                eventQueueResolver();\n   381â†’                eventQueueResolver = null;\n   382â†’              }\n   383â†’            }\n   384â†’          }\n   385â†’        } catch (error: any) {\n   386â†’          eventQueue.push({\n   387â†’            type: ResearchEventType.ERROR_OCCURRED,\n   388â†’            timestamp: new Date().toISOString(),\n   389â†’            agentName: task.agentId,\n   390â†’            data: { error: `Agent ${task.agentId} failed: ${error.message}` }\n   391â†’          });\n   392â†’        } finally {\n   393â†’          activeAgents.delete(task.agentId);\n   394â†’          completedAgents.add(task.agentId);\n   395â†’        }\n   396â†’      })(); // Execute immediately without blocking\n   397â†’    }\n   398â†’    \n   399â†’    // Stream events as they arrive - truly non-blocking\n   400â†’    const maxWaitTime = 600000; // 10 minutes for deep research\n   401â†’    const startTime = Date.now();\n   402â†’    \n   403â†’    while ((activeAgents.size > 0 || eventQueue.length > 0) && !isAborted) {\n   404â†’      // Yield any queued events immediately\n   405â†’      while (eventQueue.length > 0) {\n   406â†’        yield eventQueue.shift()!;\n   407â†’      }\n   408â†’      \n   409â†’      // Generate progressive report if enabled and enough time has passed\n   410â†’      if (progressiveReports && Date.now() - lastProgressReportTime > 5000) {\n   411â†’        const graphState = await streamingGraph.getCurrentGraph();\n   412â†’        const assessment = await streamingGraph.assessCompleteness(query);\n   413â†’        \n   414â†’        if (graphState.metadata.totalNodes > 0) {\n   415â†’          lastProgressReportTime = Date.now();\n   416â†’          \n   417â†’          yield {\n   418â†’            type: ResearchEventType.GRAPH_UPDATED,\n   419â†’            timestamp: new Date().toISOString(),\n   420â†’            data: {\n   421â†’              nodes: graphState.metadata.totalNodes,\n   422â†’              relationships: graphState.metadata.totalRelationships,\n   423â†’              coherence: assessment.coherence,\n   424â†’              completeness: assessment.completeness,\n   425â†’              depth: assessment.depth,\n   426â†’              overallQuality: assessment.overallQuality,\n   427â†’              contradictions: graphState.contradictions.length,\n   428â†’              gaps: graphState.gaps.length\n   429â†’            },\n   430â†’            confidence: assessment.overallQuality / 100\n   431â†’          };\n   432â†’        }\n   433â†’      }\n   434â†’      \n   435â†’      // Check for timeout\n   436â†’      if (Date.now() - startTime > maxWaitTime) {\n   437â†’        yield {\n   438â†’          type: ResearchEventType.ERROR_OCCURRED,\n   439â†’          timestamp: new Date().toISOString(),\n   440â†’          data: { error: 'Research timeout after 10 minutes' }\n   441â†’        };\n   442â†’        break;\n   443â†’      }\n   444â†’      \n   445â†’      // Wait for new events or timeout\n   446â†’      await Promise.race([\n   447â†’        new Promise<void>(resolve => {\n   448â†’          eventQueueResolver = resolve;\n   449â†’          // Also resolve after a short timeout to check other conditions\n   450â†’          setTimeout(resolve, 100);\n   451â†’        }),\n   452â†’        new Promise(resolve => setTimeout(resolve, 100))\n   453â†’      ]);\n   454â†’    }\n   455â†’    \n   456â†’    // Step 3: Get the final knowledge graph from streaming agent\n   457â†’    // The graph has been built incrementally during streaming\n   458â†’    knowledgeGraph = await streamingGraph.getCurrentGraph();\n   459â†’    \n   460â†’    // Emit final graph state\n   461â†’    if (knowledgeGraph && knowledgeGraph.metadata.totalNodes > 0) {\n   462â†’      yield {\n   463â†’        type: ResearchEventType.GRAPH_UPDATED,\n   464â†’        timestamp: new Date().toISOString(),\n   465â†’        data: {\n   466â†’          nodes: knowledgeGraph.metadata.totalNodes,\n   467â†’          relationships: knowledgeGraph.metadata.totalRelationships,\n   468â†’          contradictions: knowledgeGraph.contradictions.length,\n   469â†’          gaps: knowledgeGraph.gaps.length,\n   470â†’          message: 'Final knowledge graph state'\n   471â†’        }\n   472â†’      };\n   473â†’      \n   474â†’      // Ensure final state is persisted to Neo4j\n   475â†’      await neo4jStorage.storeGraph(knowledgeGraph).catch(err => {\n   476â†’        console.error(`Final Neo4j store failed: ${err.message}`);\n   477â†’      });\n   478â†’    }\n   479â†’    \n   480â†’    // Step 4: Continuous quality assessment with streaming\n   481â†’    while (iterationCount < maxIterations && currentQualityScore < qualityThreshold) {\n   482â†’      // Get current graph state for assessment\n   483â†’      const currentGraphState = await streamingGraph.getCurrentGraph();\n   484â†’      const collectedInsights = currentGraphState.insights || [];\n   485â†’      \n   486â†’      // Assess quality with actual content\n   487â†’      const qualityResult = await qualityAssessmentAgent.generate(\n   488â†’        [{ \n   489â†’          role: 'user', \n   490â†’          content: `Assess the quality of research on \"${query}\" based on:\n   491â†’          \n   492â†’          Knowledge Graph Statistics:\n   493â†’          - Nodes: ${currentGraphState.metadata?.totalNodes || 0}\n   494â†’          - Relationships: ${currentGraphState.metadata?.totalRelationships || 0}\n   495â†’          - Insights collected: ${collectedInsights.length}\n   496â†’          \n   497â†’          Sample Insights:\n   498â†’          ${collectedInsights.slice(0, 5).map(i => `- ${i.insight}`).join('\\n')}\n   499â†’          \n   500â†’          Evaluate completeness (coverage of topic), coherence (logical connections), depth (detail level), and overall quality.\n   501â†’          Return scores from 0-100 for each metric.` \n   502â†’        }],\n   503â†’        {\n   504â†’          experimental_output: z.object({\n   505â†’            completeness: z.number(),\n   506â†’            coherence: z.number(),\n   507â†’            depth: z.number(),\n   508â†’            overallQuality: z.number()\n   509â†’          })\n   510â†’        }\n   511â†’      );\n   512â†’      \n   513â†’      currentQualityScore = qualityResult.object.overallQuality;\n   514â†’      \n   515â†’      yield {\n   516â†’        type: ResearchEventType.QUALITY_ASSESSED,\n   517â†’        timestamp: new Date().toISOString(),\n   518â†’        data: {\n   519â†’          scores: qualityResult.object,\n   520â†’          iteration: iterationCount + 1\n   521â†’        },\n   522â†’        confidence: currentQualityScore / 100\n   523â†’      };\n   524â†’      \n   525â†’      // Check if we should continue\n   526â†’      if (currentQualityScore >= qualityThreshold) {\n   527â†’        break;\n   528â†’      }\n   529â†’      \n   530â†’      // Step 5: Parallel refinement if needed\n   531â†’      if (iterationCount < maxIterations - 1) {\n   532â†’        const gaps = knowledgeGraph?.gaps || [];\n   533â†’        \n   534â†’        // Add defensive check to ensure gaps are related to the original query\n   535â†’        const relevantGaps = gaps.filter(gap => {\n   536â†’          // Check if the gap is actually related to the original query\n   537â†’          const queryLower = query.toLowerCase();\n   538â†’          const gapLower = gap.area.toLowerCase();\n   539â†’          const suggestedQueriesLower = gap.suggestedQueries.map(q => q.toLowerCase());\n   540â†’          \n   541â†’          // Simple relevance check - at least one query term should appear in the gap or its queries\n   542â†’          const queryTerms = queryLower.split(/[\\s,;]+/).filter(t => t.length > 3);\n   543â†’          const isRelevant = queryTerms.some(term => \n   544â†’            gapLower.includes(term) || \n   545â†’            suggestedQueriesLower.some(q => q.includes(term))\n   546â†’          );\n   547â†’          \n   548â†’          if (!isRelevant) {\n   549â†’            console.log(`âš ï¸ Filtering out unrelated gap: \"${gap.area}\"`);\n   550â†’          }\n   551â†’          \n   552â†’          return isRelevant && (gap.importance === 'critical' || gap.importance === 'high');\n   553â†’        });\n   554â†’        \n   555â†’        const refinementQueries = relevantGaps\n   556â†’          .slice(0, parallelAgents)\n   557â†’          .flatMap(gap => gap.suggestedQueries);\n   558â†’        \n   559â†’        if (refinementQueries.length > 0) {\n   560â†’          // Execute parallel refinement\n   561â†’          const refinementPromises = refinementQueries.map(async (query, index) => {\n   562â†’            const agentName = `Refinement Agent ${index + 1}`;\n   563â†’            \n   564â†’            // Emit activation event before starting\n   565â†’            console.log(`Activating ${agentName} for query: ${query}`);\n   566â†’            \n   567â†’            return {\n   568â†’              agentName,\n   569â†’              query,\n   570â†’              result: await researchAgent.generate(\n   571â†’                [{ role: 'user', content: `Refine research: ${query}` }],\n   572â†’                { maxSteps: 5 }\n   573â†’              )\n   574â†’            };\n   575â†’          });\n   576â†’          \n   577â†’          const refinementResults = await Promise.all(refinementPromises);\n   578â†’          \n   579â†’          // Emit activation events and update graph with refinements\n   580â†’          for (const refinement of refinementResults) {\n   581â†’            // Emit activation event\n   582â†’            yield {\n   583â†’              type: ResearchEventType.AGENT_ACTIVATED,\n   584â†’              timestamp: new Date().toISOString(),\n   585â†’              agentName: refinement.agentName,\n   586â†’              data: { query: refinement.query }\n   587â†’            };\n   588â†’            \n   589â†’            if (refinement.result.object) {\n   590â†’              knowledgeGraph = await buildKnowledgeGraph(refinement.result.object, knowledgeGraph, query);\n   591â†’              \n   592â†’              yield {\n   593â†’                type: ResearchEventType.GRAPH_UPDATED,\n   594â†’                timestamp: new Date().toISOString(),\n   595â†’                data: {\n   596â†’                  nodes: knowledgeGraph.nodes.length,\n   597â†’                  relationships: knowledgeGraph.relationships.length,\n   598â†’                  refinementApplied: true\n   599â†’                }\n   600â†’              };\n   601â†’            }\n   602â†’          }\n   603â†’        }\n   604â†’      }\n   605â†’      \n   606â†’      iterationCount++;\n   607â†’      \n   608â†’      yield {\n   609â†’        type: ResearchEventType.ITERATION_COMPLETE,\n   610â†’        timestamp: new Date().toISOString(),\n   611â†’        data: {\n   612â†’          iteration: iterationCount,\n   613â†’          qualityScore: currentQualityScore,\n   614â†’          continueRefining: iterationCount < maxIterations\n   615â†’        }\n   616â†’      };\n   617â†’    }\n   618â†’    \n   619â†’    // Generate final comprehensive report with knowledge graph insights\n   620â†’    const finalAssessment = await streamingGraph.assessCompleteness(query);\n   621â†’    \n   622â†’    // Generate rich final report using report agent with graph insights\n   623â†’    let finalReport = '';\n   624â†’    if (knowledgeGraph && knowledgeGraph.metadata.totalNodes > 0) {\n   625â†’      try {\n   626â†’        // Ensure we have actual insights to report on\n   627â†’        const actualInsights = knowledgeGraph.insights || [];\n   628â†’        const insightTexts = actualInsights.map(i => i.insight || i).filter(Boolean);\n   629â†’        \n   630â†’        const reportResult = await reportAgent.generate(\n   631â†’          [{\n   632â†’            role: 'user',\n   633â†’            content: `Generate a comprehensive research report for the query: \"${query}\"\n   634â†’            \n   635â†’            ACTUAL RESEARCH FINDINGS (USE ONLY THESE - DO NOT HALLUCINATE):\n   636â†’            ${insightTexts.map((insight, idx) => `${idx + 1}. ${insight}`).join('\\n')}\n   637â†’            \n   638â†’            Knowledge Graph Metrics:\n   639â†’            - Total Entities: ${knowledgeGraph.metadata.totalNodes}\n   640â†’            - Total Relationships: ${knowledgeGraph.metadata.totalRelationships}\n   641â†’            - Research Completeness: ${finalAssessment.completeness.toFixed(1)}%\n   642â†’            - Information Coherence: ${finalAssessment.coherence.toFixed(1)}%\n   643â†’            - Analysis Depth: ${finalAssessment.depth.toFixed(1)}%\n   644â†’            - Overall Quality Score: ${finalAssessment.overallQuality.toFixed(1)}%\n   645â†’            \n   646â†’            ${knowledgeGraph.contradictions.length > 0 ? `Contradictions Found: ${knowledgeGraph.contradictions.length}` : 'No contradictions detected'}\n   647â†’            ${knowledgeGraph.gaps.length > 0 ? `Knowledge Gaps Identified: ${knowledgeGraph.gaps.map(g => g.area).join(', ')}` : ''}\n   648â†’            \n   649â†’            Instructions:\n   650â†’            1. Synthesize ONLY the provided insights above\n   651â†’            2. DO NOT add information not present in the insights\n   652â†’            3. Structure the report with clear sections\n   653â†’            4. Highlight key findings and their implications\n   654â†’            5. Maintain factual accuracy based on the collected data`\n   655â†’          }],\n   656â†’          { maxSteps: 3 }\n   657â†’        );\n   658â†’        \n   659â†’        if (reportResult.text) {\n   660â†’          finalReport = reportResult.text;\n   661â†’        }\n   662â†’      } catch (error) {\n   663â†’        console.error('Report generation error:', error);\n   664â†’        finalReport = `Research Report for: ${query}\\n\\nKey Findings:\\n${knowledgeGraph.insights.slice(0, 10).map(i => `- ${i.insight}`).join('\\n')}\\n\\nNote: Full report generation encountered an error.`;\n   665â†’      }\n   666â†’    }\n   667â†’    \n   668â†’    // Final event with knowledge graph data\n   669â†’    yield {\n   670â†’      type: ResearchEventType.RESEARCH_COMPLETE,\n   671â†’      timestamp: new Date().toISOString(),\n   672â†’      data: {\n   673â†’        finalQualityScore: currentQualityScore || finalAssessment.overallQuality,\n   674â†’        totalIterations: iterationCount,\n   675â†’        totalInsights: totalInsightsProcessed,\n   676â†’        graphSize: {\n   677â†’          nodes: knowledgeGraph?.metadata.totalNodes || 0,\n   678â†’          relationships: knowledgeGraph?.metadata.totalRelationships || 0\n   679â†’        },\n   680â†’        knowledgeGraphMetrics: {\n   681â†’          completeness: finalAssessment.completeness,\n   682â†’          coherence: finalAssessment.coherence,\n   683â†’          depth: finalAssessment.depth,\n   684â†’          contradictions: knowledgeGraph?.contradictions.length || 0,\n   685â†’          gaps: knowledgeGraph?.gaps.length || 0\n   686â†’        },\n   687â†’        insights: knowledgeGraph?.insights || [],\n   688â†’        report: finalReport\n   689â†’      }\n   690â†’    };\n   691â†’    \n   692â†’  } catch (error: any) {\n   693â†’    yield {\n   694â†’      type: ResearchEventType.ERROR_OCCURRED,\n   695â†’      timestamp: new Date().toISOString(),\n   696â†’      data: {\n   697â†’        error: error.message,\n   698â†’        stack: error.stack\n   699â†’      }\n   700â†’    };\n   701â†’  }\n   702â†’}\n   703â†’\n   704â†’// Helper function to consume the stream with a callback\n   705â†’export async function streamResearchWithCallback(\n   706â†’  query: string,\n   707â†’  onEvent: (event: ResearchEvent) => void,\n   708â†’  options?: {\n   709â†’    maxIterations?: number;\n   710â†’    qualityThreshold?: number;\n   711â†’    parallelAgents?: number;\n   712â†’    abortSignal?: AbortSignal;\n   713â†’  }\n   714â†’): Promise<void> {\n   715â†’  const stream = executeStreamingResearch(query, options);\n   716â†’  \n   717â†’  for await (const event of stream) {\n   718â†’    onEvent(event);\n   719â†’  }\n   720â†’}\n   721â†’\n   722â†’// Helper function to collect all events into an array\n   723â†’export async function collectResearchEvents(\n   724â†’  query: string,\n   725â†’  options?: {\n   726â†’    maxIterations?: number;\n   727â†’    qualityThreshold?: number;\n   728â†’    parallelAgents?: number;\n   729â†’    abortSignal?: AbortSignal;\n   730â†’  }\n   731â†’): Promise<ResearchEvent[]> {\n   732â†’  const events: ResearchEvent[] = [];\n   733â†’  const stream = executeStreamingResearch(query, options);\n   734â†’  \n   735â†’  for await (const event of stream) {\n   736â†’    events.push(event);\n   737â†’  }\n   738â†’  \n   739â†’  return events;\n   740â†’}\n   741â†’\n   742â†’// Backward compatibility wrapper for synchronous execution\n   743â†’export async function executeStreamingResearchSync(\n   744â†’  query: string,\n   745â†’  options?: {\n   746â†’    maxIterations?: number;\n   747â†’    qualityThreshold?: number;\n   748â†’    parallelAgents?: number;\n   749â†’  }\n   750â†’): Promise<{\n   751â†’  success: boolean;\n   752â†’  researchData: any;\n   753â†’  qualityScore: number;\n   754â†’  iterations: number;\n   755â†’  report?: string;\n   756â†’  knowledgeGraph?: KnowledgeGraph;\n   757â†’  insights: any[];\n   758â†’}> {\n   759â†’  const events = await collectResearchEvents(query, options);\n   760â†’  \n   761â†’  // Synthesize events into traditional result format\n   762â†’  let finalQualityScore = 0;\n   763â†’  let totalIterations = 0;\n   764â†’  let knowledgeGraph: KnowledgeGraph | null = null;\n   765â†’  const insights: any[] = [];\n   766â†’  const researchData: any = { queries: [], searchResults: [], learnings: [] };\n   767â†’  \n   768â†’  for (const event of events) {\n   769â†’    switch (event.type) {\n   770â†’      case ResearchEventType.INSIGHT_DISCOVERED:\n   771â†’        insights.push(event.data);\n   772â†’        if (event.data.insight) {\n   773â†’          researchData.learnings.push({\n   774â†’            learning: event.data.insight,\n   775â†’            source: event.data.source,\n   776â†’            followUpQuestions: event.data.followUpQuestions || []\n   777â†’          });\n   778â†’        }\n   779â†’        break;\n   780â†’      case ResearchEventType.QUALITY_ASSESSED:\n   781â†’        finalQualityScore = event.data.scores?.overallQuality || finalQualityScore;\n   782â†’        break;\n   783â†’      case ResearchEventType.ITERATION_COMPLETE:\n   784â†’        totalIterations = event.data.iteration;\n   785â†’        break;\n   786â†’      case ResearchEventType.RESEARCH_COMPLETE:\n   787â†’        finalQualityScore = event.data.finalQualityScore || finalQualityScore;\n   788â†’        totalIterations = event.data.totalIterations || totalIterations;\n   789â†’        if (event.data.insights) {\n   790â†’          insights.push(...event.data.insights);\n   791â†’        }\n   792â†’        break;\n   793â†’      case ResearchEventType.GRAPH_UPDATED:\n   794â†’        // Track the latest graph state\n   795â†’        if (event.data) {\n   796â†’          knowledgeGraph = {\n   797â†’            nodes: new Array(event.data.nodes).fill({}),\n   798â†’            relationships: new Array(event.data.relationships).fill({}),\n   799â†’            insights: event.data.newInsights ? new Array(event.data.newInsights).fill({}) : [],\n   800â†’            contradictions: [],\n   801â†’            gaps: [],\n   802â†’            metadata: {\n   803â†’              createdAt: new Date().toISOString(),\n   804â†’              lastUpdated: new Date().toISOString(),\n   805â†’              version: '1.0',\n   806â†’              source: 'streaming-research'\n   807â†’            }\n   808â†’          } as KnowledgeGraph;\n   809â†’        }\n   810â†’        break;\n   811â†’    }\n   812â†’  }\n   813â†’  \n   814â†’  // Generate report from insights\n   815â†’  const report = insights.length > 0 \n   816â†’    ? `Research Report\\n\\nKey Insights:\\n${insights.map(i => `- ${i.insight || i}`).join('\\n')}\\n\\nTotal iterations: ${totalIterations}\\nFinal quality score: ${finalQualityScore}`\n   817â†’    : undefined;\n   818â†’  \n   819â†’  return {\n   820â†’    success: finalQualityScore >= 60,\n   821â†’    researchData,\n   822â†’    qualityScore: finalQualityScore,\n   823â†’    iterations: totalIterations,\n   824â†’    report,\n   825â†’    knowledgeGraph: knowledgeGraph || undefined,\n   826â†’    insights\n   827â†’  };\n   828â†’}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "text",
        "text": "Now let me read the other key files mentioned in the task to understand the complete pipeline:"
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01EjMbNUMLumYJgs1b7T5QSB",
        "name": "Read",
        "input": {
          "file_path": "/mnt/c/Users/caleb/Desktop/GithubProjects/deepfield/src/mastra/agents/researchAgent.ts"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01WmmfTS3rJd3jXDP1DcGaUC",
        "name": "Read",
        "input": {
          "file_path": "/mnt/c/Users/caleb/Desktop/GithubProjects/deepfield/src/mastra/agents/reportAgent.ts"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01G9xCBjHQvF9P1WXqMhDux6",
        "name": "Read",
        "input": {
          "file_path": "/mnt/c/Users/caleb/Desktop/GithubProjects/deepfield/src/mastra/agents/learningExtractionAgent.ts"
        }
      }
    ]
  },
  {
    "role": "assistant",
    "content": [
      {
        "type": "tool_use",
        "id": "toolu_01HdpGH4VjmXaznbfdNv694J",
        "name": "Read",
        "input": {
          "file_path": "/mnt/c/Users/caleb/Desktop/GithubProjects/deepfield/src/mastra/storage/neo4jStorage.ts"
        }
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01EjMbNUMLumYJgs1b7T5QSB",
        "type": "tool_result",
        "content": "     1â†’import { openai } from '@ai-sdk/openai';\n     2â†’import { Agent } from '@mastra/core/agent';\n     3â†’import { evaluateResultTool } from '../tools/evaluateResultTool';\n     4â†’import { extractLearningsTool } from '../tools/extractLearningsTool';\n     5â†’import { webSearchTool } from '../tools/webSearchTool';\n     6â†’\n     7â†’const mainModel = openai('gpt-4.1-mini');\n     8â†’\n     9â†’export const researchAgent = new Agent({\n    10â†’  name: 'Research Agent',\n    11â†’  instructions: `You are an expert research agent. Your goal is to research topics thoroughly by following this EXACT process:\n    12â†’\n    13â†’  **PHASE 1: Initial Research**\n    14â†’  1. Break down the main topic into 2 specific, focused search queries\n    15â†’  2. For each query, use the webSearchTool to search the web\n    16â†’  3. Use evaluateResultTool to determine if results are relevant\n    17â†’  4. For relevant results, use extractLearningsTool to extract key learnings and follow-up questions\n    18â†’\n    19â†’  **PHASE 2: Follow-up Research**\n    20â†’  1. After completing Phase 1, collect ALL follow-up questions from the extracted learnings\n    21â†’  2. Search for each follow-up question using webSearchTool\n    22â†’  3. Use evaluateResultTool and extractLearningsTool on these follow-up results\n    23â†’  4. **STOP after Phase 2 - do NOT search additional follow-up questions from Phase 2 results**\n    24â†’\n    25â†’  **Important Guidelines:**\n    26â†’  - Keep search queries focused and specific - avoid overly general queries\n    27â†’  - Track all completed queries to avoid repetition\n    28â†’  - Only search follow-up questions from the FIRST round of learnings\n    29â†’  - Do NOT create infinite loops by searching follow-up questions from follow-up results\n    30â†’\n    31â†’  **Output Structure:**\n    32â†’  Return findings in JSON format with:\n    33â†’  - queries: Array of all search queries used (initial + follow-up)\n    34â†’  - searchResults: Array of relevant search results found\n    35â†’  - learnings: Array of key learnings extracted from results\n    36â†’  - completedQueries: Array tracking what has been searched\n    37â†’  - phase: Current phase of research (\"initial\" or \"follow-up\")\n    38â†’\n    39â†’  **Error Handling:**\n    40â†’  - If all searches fail, use your knowledge to provide basic information\n    41â†’  - Always complete the research process even if some searches fail\n    42â†’\n    43â†’  Use all the tools available to you systematically and stop after the follow-up phase.\n    44â†’  `,\n    45â†’  model: mainModel,\n    46â†’  tools: {\n    47â†’    webSearchTool,\n    48â†’    evaluateResultTool,\n    49â†’    extractLearningsTool,\n    50â†’  },\n    51â†’});\n    52â†’\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "tool_use_id": "toolu_01WmmfTS3rJd3jXDP1DcGaUC",
        "type": "tool_result",
        "content": "     1â†’import { Agent } from '@mastra/core/agent';\n     2â†’import { openai } from '@ai-sdk/openai';\n     3â†’\n     4â†’const reportModel = openai('gpt-4.1-mini');\n     5â†’\n     6â†’export const reportAgent = new Agent({\n     7â†’  name: 'Report Agent',\n     8â†’  instructions: `You are an expert researcher. Today is ${new Date().toISOString()}. Follow these instructions when responding:\n     9â†’  - You may be asked to research subjects that are after your knowledge cutoff, assume the user is right when presented with news.\n    10â†’  - The user is a highly experienced analyst, no need to simplify it, be as detailed as possible and make sure your response is correct.\n    11â†’  - Be highly organized.\n    12â†’  - Suggest solutions that I didn't think about.\n    13â†’  - Be proactive and anticipate my needs.\n    14â†’  - Treat me as an expert in all subject matter.\n    15â†’  - Mistakes erode my trust, so be accurate and thorough.\n    16â†’  - Provide detailed explanations, I'm comfortable with lots of detail.\n    17â†’  - Value good arguments over authorities, the source is irrelevant.\n    18â†’  - Consider new technologies and contrarian ideas, not just the conventional wisdom.\n    19â†’  - You may use high levels of speculation or prediction, just flag it for me.\n    20â†’  - Use Markdown formatting.\n    21â†’\n    22â†’  Your task is to generate comprehensive reports based on research data that includes:\n    23â†’  - Search queries used\n    24â†’  - Relevant search results\n    25â†’  - Key learnings extracted from those results\n    26â†’  - Follow-up questions identified\n    27â†’\n    28â†’  Structure your reports with clear sections, headings, and focus on synthesizing the information\n    29â†’  into a cohesive narrative rather than simply listing facts.`,\n    30â†’  model: reportModel,\n    31â†’});\n    32â†’\n\n<system-reminder>\nWhenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.\n</system-reminder>\n"
      }
    ]
  }
]